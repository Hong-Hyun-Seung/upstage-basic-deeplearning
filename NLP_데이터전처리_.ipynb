{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "[필수1] (Problem) 데이터전처리 .ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0PF647j4W93"
      },
      "source": [
        "# Natural Language Processing\n",
        "## 필수과제 1: 데이터 전처리\n",
        "\n",
        "### 0. Introduction\n",
        "\n",
        "- 본 과제의 목적은 자연어처리 모델에 활용하는 데이터를 전처리하는 것입니다.  [Spacy](https://spacy.io/) 를 활용한 영어 데이터 전처리와, [Konlpy](https://konlpy.org/ko/latest/) 를 활용한 한국어 데이터 전처리 기법을 익힙니다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "M1c3kfN0nuq-"
      },
      "source": [
        "## 1. Spacy를 이용한 영어 전처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A-_HUiKMUAd8"
      },
      "source": [
        "import spacy\n",
        "spacy_en = spacy.load('en')"
      ],
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0JzKRDIBUEfd"
      },
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y2aruQ5dYMBM"
      },
      "source": [
        "### 1.1 Tokenezation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZNVS9mSTUJ7L",
        "outputId": "b4574c04-edb8-40ba-dfd3-0d2e50fd7a2a",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "text = nlp('Naver Connect and Upstage Boostcamp')\n",
        "print ([token.text for token in text])"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Naver', 'Connect', 'and', 'Upstage', 'Boostcamp']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q4ykKX1BUUI1",
        "outputId": "96d39b25-3f17-43cc-be40-19bb870a1dfe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "doc = nlp('This assignment is about Natural Language Processing.' 'In this assignment, we will do preprocessing')\n",
        "print ([token.text for token in doc])"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['This', 'assignment', 'is', 'about', 'Natural', 'Language', 'Processing', '.', 'In', 'this', 'assignment', ',', 'we', 'will', 'do', 'preprocessing']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8Xlhp12rV34q"
      },
      "source": [
        "text=nlp(\"The film's development began when Marvel Studios received a loan from Merrill Lynch in April 2005. After the success of the film Iron Man in May 2008, \\\n",
        "Marvel announced that The Avengers would be released in July 2011 and would bring together Tony Stark, Steve Rogers, Bruce Banner, and Thor from Marvel's previous films. \\\n",
        "With the signing of Johansson as Natasha Romanoff in March 2009, the film was pushed back for a 2012 release. Whedon was brought on board in April 2010 and rewrote the original screenplay by Zak Penn. Production began in April 2011 in Albuquerque, \\\n",
        "New Mexico, before moving to Cleveland, Ohio in August and New York City in September. The film has more than 2,200 visual effects shots.\")"
      ],
      "execution_count": 60,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2p_K3q3BRoj",
        "outputId": "79c31732-6b62-4dfd-bd49-01de30a475a2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print([token.text for token in text])"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['The', 'film', \"'s\", 'development', 'began', 'when', 'Marvel', 'Studios', 'received', 'a', 'loan', 'from', 'Merrill', 'Lynch', 'in', 'April', '2005', '.', 'After', 'the', 'success', 'of', 'the', 'film', 'Iron', 'Man', 'in', 'May', '2008', ',', 'Marvel', 'announced', 'that', 'The', 'Avengers', 'would', 'be', 'released', 'in', 'July', '2011', 'and', 'would', 'bring', 'together', 'Tony', 'Stark', ',', 'Steve', 'Rogers', ',', 'Bruce', 'Banner', ',', 'and', 'Thor', 'from', 'Marvel', \"'s\", 'previous', 'films', '.', 'With', 'the', 'signing', 'of', 'Johansson', 'as', 'Natasha', 'Romanoff', 'in', 'March', '2009', ',', 'the', 'film', 'was', 'pushed', 'back', 'for', 'a', '2012', 'release', '.', 'Whedon', 'was', 'brought', 'on', 'board', 'in', 'April', '2010', 'and', 'rewrote', 'the', 'original', 'screenplay', 'by', 'Zak', 'Penn', '.', 'Production', 'began', 'in', 'April', '2011', 'in', 'Albuquerque', ',', 'New', 'Mexico', ',', 'before', 'moving', 'to', 'Cleveland', ',', 'Ohio', 'in', 'August', 'and', 'New', 'York', 'City', 'in', 'September', '.', 'The', 'film', 'has', 'more', 'than', '2,200', 'visual', 'effects', 'shots', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SfKx_fOZYyfp"
      },
      "source": [
        "### 1.2 불용어 (Stopword)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dVo5YsbhCbP1"
      },
      "source": [
        "불용어(Stop word)는 분석에 큰 의미가 없는 단어를 지칭합니다. 예를 들어 the, a, an, is, I, my 등과 같이 문장을 구성하는 필수 요소지만 문맥적으로 큰 의미가 없는 단어가 이에 속합니다"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "No59QbQyVZ2k",
        "outputId": "fba14447-4f38-49a8-bbb6-fb060b3743f2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "for stop_word in list(spacy_stopwords)[:30]:\n",
        "  print(stop_word)"
      ],
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "could\n",
            "also\n",
            "what\n",
            "less\n",
            "himself\n",
            "off\n",
            "four\n",
            "across\n",
            "a\n",
            "keep\n",
            "twenty\n",
            "whereupon\n",
            "forty\n",
            "’d\n",
            "'ll\n",
            "this\n",
            "them\n",
            "last\n",
            "been\n",
            "unless\n",
            "were\n",
            "move\n",
            "was\n",
            "well\n",
            "regarding\n",
            "how\n",
            "‘s\n",
            "but\n",
            "first\n",
            "is\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uuAshJZ_Vfj-",
        "outputId": "6eedd4d9-9e19-4935-feea-e67aa628d661",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "stopword_text = [token for token in text if not token.is_stop]\n",
        "print(stopword_text)"
      ],
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[film, development, began, Marvel, Studios, received, loan, Merrill, Lynch, April, 2005, ., success, film, Iron, Man, 2008, ,, Marvel, announced, Avengers, released, July, 2011, bring, Tony, Stark, ,, Steve, Rogers, ,, Bruce, Banner, ,, Thor, Marvel, previous, films, ., signing, Johansson, Natasha, Romanoff, March, 2009, ,, film, pushed, 2012, release, ., Whedon, brought, board, April, 2010, rewrote, original, screenplay, Zak, Penn, ., Production, began, April, 2011, Albuquerque, ,, New, Mexico, ,, moving, Cleveland, ,, Ohio, August, New, York, City, September, ., film, 2,200, visual, effects, shots, .]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H6Xoxy6SY9m8"
      },
      "source": [
        "### 1.3 Lemmatization "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vPDccv8yW9jS",
        "outputId": "0d81dbd1-c3f5-451f-e5d3-c84d51b07df0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "for token in text[:20]:\n",
        "  print (token, \"-\", token.lemma_)"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The - the\n",
            "film - film\n",
            "'s - 's\n",
            "development - development\n",
            "began - begin\n",
            "when - when\n",
            "Marvel - Marvel\n",
            "Studios - Studios\n",
            "received - receive\n",
            "a - a\n",
            "loan - loan\n",
            "from - from\n",
            "Merrill - Merrill\n",
            "Lynch - Lynch\n",
            "in - in\n",
            "April - April\n",
            "2005 - 2005\n",
            ". - .\n",
            "After - after\n",
            "the - the\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2QU2ZNFDZhjC"
      },
      "source": [
        "### 1.4 그외 token class의 attributes \n",
        "\n",
        "https://spacy.io/api/token#attributes"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q6wAEJBQXPiK",
        "outputId": "baeb5ef6-c1b3-44a7-9f19-5b8a8b552cfc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(\"token \\t is_punct \\t is_space \\t shape_ \\t is_stop\")\n",
        "print(\"=\"*70)\n",
        "for token in text[21:31]:\n",
        "  print(token,\"\\t\", token.is_punct, \"\\t\\t\",token.is_space,\"\\t\\t\", token.shape_, \"\\t\\t\",token.is_stop)"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "token \t is_punct \t is_space \t shape_ \t is_stop\n",
            "======================================================================\n",
            "of \t False \t\t False \t\t xx \t\t True\n",
            "the \t False \t\t False \t\t xxx \t\t True\n",
            "film \t False \t\t False \t\t xxxx \t\t False\n",
            "Iron \t False \t\t False \t\t Xxxx \t\t False\n",
            "Man \t False \t\t False \t\t Xxx \t\t False\n",
            "in \t False \t\t False \t\t xx \t\t True\n",
            "May \t False \t\t False \t\t Xxx \t\t True\n",
            "2008 \t False \t\t False \t\t dddd \t\t False\n",
            ", \t True \t\t False \t\t , \t\t False\n",
            "Marvel \t False \t\t False \t\t Xxxxx \t\t False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "saa9trANZhKI"
      },
      "source": [
        "## 빈칸완성 과제1"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jK-IdgoiZVoJ"
      },
      "source": [
        "def is_token_allowed(token):\n",
        "# stopword와 punctutation을 제거해주세요.\n",
        "  spacy_stopwords = spacy.lang.en.stop_words.STOP_WORDS\n",
        "  #if문을 작성해주세요.\n",
        "  \n",
        "  ##TODO#\n",
        "  if  token.is_stop:\n",
        "  ##TODO##\n",
        "    return False\n",
        "  elif token.is_punct:\n",
        "    return False\n",
        "  else:\n",
        "    return True\n",
        "\n",
        "def preprocess_token(token):\n",
        "    return token.lemma_.strip().lower()\n",
        "  \n",
        "filtered_tokens = [preprocess_token(token) for token in text if is_token_allowed(token)]\n",
        "answer=['film', 'development','begin', 'marvel','studios', 'receive','loan', 'merrill','lynch', 'april','2005', 'success','film', 'iron','man', '2008','marvel','announce', 'avengers','release', 'july','2011', 'bring','tony', 'stark','steve', 'rogers','bruce', 'banner','thor', 'marvel','previous', 'film','signing', 'johansson','natasha','romanoff','march','2009','film','push','2012','release','whedon','bring','board','april','2010','rewrote','original','screenplay','zak','penn','production','begin','april','2011','albuquerque','new','mexico','move','cleveland','ohio','august','new','york','city','september','film','2,200','visual','effect','shot']\n",
        "assert filtered_tokens == answer"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htdYW5Gcc_Ii"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dv92V7lFnpYt"
      },
      "source": [
        "## 2. 한국어 전처리"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mWdfTvNnoZaX"
      },
      "source": [
        "### 2.1 Mecab를 이용한 형태소 분석 기반 토크나이징"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-UHPPZuBdBkN",
        "outputId": "a93755bf-94fe-4e07-b86b-ed7657657537",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "!git clone https://github.com/SOMJANG/Mecab-ko-for-Google-Colab.git\n",
        "%cd Mecab-ko-for-Google-Colab\n",
        "!bash install_mecab-ko_on_colab190912.sh"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'Mecab-ko-for-Google-Colab'...\n",
            "remote: Enumerating objects: 91, done.\u001b[K\n",
            "remote: Counting objects: 100% (91/91), done.\u001b[K\n",
            "remote: Compressing objects: 100% (85/85), done.\u001b[K\n",
            "remote: Total 91 (delta 43), reused 22 (delta 6), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (91/91), done.\n",
            "/content/Mecab-ko-for-Google-Colab\n",
            "Installing konlpy.....\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 6.4 MB/s \n",
            "\u001b[?25hCollecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 6.1 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 34.9 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n",
            "Done\n",
            "Installing mecab-0.996-ko-0.9.2.tar.gz.....\n",
            "Downloading mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "--2021-09-07 08:33:56--  https://bitbucket.org/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::22c3:9b0a, 2406:da00:ff00::34cc:ea4a, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=y5batrC8%2BspsUebtZ8opFdeaVWg%3D&Expires=1631004819&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-09-07 08:33:56--  https://bbuseruploads.s3.amazonaws.com/eunjeon/mecab-ko/downloads/mecab-0.996-ko-0.9.2.tar.gz?Signature=y5batrC8%2BspsUebtZ8opFdeaVWg%3D&Expires=1631004819&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=null&response-content-disposition=attachment%3B%20filename%3D%22mecab-0.996-ko-0.9.2.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.168.65\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.168.65|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 1414979 (1.3M) [application/x-tar]\n",
            "Saving to: ‘mecab-0.996-ko-0.9.2.tar.gz’\n",
            "\n",
            "mecab-0.996-ko-0.9. 100%[===================>]   1.35M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2021-09-07 08:33:56 (10.5 MB/s) - ‘mecab-0.996-ko-0.9.2.tar.gz’ saved [1414979/1414979]\n",
            "\n",
            "Done\n",
            "Unpacking mecab-0.996-ko-0.9.2.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-0.996-ko-0.9.2.......\n",
            "installing mecab-0.996-ko-0.9.2.tar.gz........\n",
            "configure\n",
            "make\n",
            "make check\n",
            "make install\n",
            "ldconfig\n",
            "Done\n",
            "Change Directory to /content\n",
            "Downloading mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "from https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "--2021-09-07 08:35:24--  https://bitbucket.org/eunjeon/mecab-ko-dic/downloads/mecab-ko-dic-2.1.1-20180720.tar.gz\n",
            "Resolving bitbucket.org (bitbucket.org)... 104.192.141.1, 2406:da00:ff00::34cc:ea4a, 2406:da00:ff00::22c3:9b0a, ...\n",
            "Connecting to bitbucket.org (bitbucket.org)|104.192.141.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=2O1%2F6BMFYBZeMiiN69CMi5OvHLY%3D&Expires=1631005524&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None [following]\n",
            "--2021-09-07 08:35:24--  https://bbuseruploads.s3.amazonaws.com/a4fcd83e-34f1-454e-a6ac-c242c7d434d3/downloads/b5a0c703-7b64-45ed-a2d7-180e962710b6/mecab-ko-dic-2.1.1-20180720.tar.gz?Signature=2O1%2F6BMFYBZeMiiN69CMi5OvHLY%3D&Expires=1631005524&AWSAccessKeyId=AKIA6KOSE3BNJRRFUUX6&versionId=tzyxc1TtnZU_zEuaaQDGN4F76hPDpyFq&response-content-disposition=attachment%3B%20filename%3D%22mecab-ko-dic-2.1.1-20180720.tar.gz%22&response-content-encoding=None\n",
            "Resolving bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)... 52.217.139.241\n",
            "Connecting to bbuseruploads.s3.amazonaws.com (bbuseruploads.s3.amazonaws.com)|52.217.139.241|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 49775061 (47M) [application/x-tar]\n",
            "Saving to: ‘mecab-ko-dic-2.1.1-20180720.tar.gz’\n",
            "\n",
            "mecab-ko-dic-2.1.1- 100%[===================>]  47.47M  78.9MB/s    in 0.6s    \n",
            "\n",
            "2021-09-07 08:35:25 (78.9 MB/s) - ‘mecab-ko-dic-2.1.1-20180720.tar.gz’ saved [49775061/49775061]\n",
            "\n",
            "Done\n",
            "Unpacking  mecab-ko-dic-2.1.1-20180720.tar.gz.......\n",
            "Done\n",
            "Change Directory to mecab-ko-dic-2.1.1-20180720\n",
            "Done\n",
            "installing........\n",
            "configure\n",
            "make\n",
            "make install\n",
            "apt-get update\n",
            "apt-get upgrade\n",
            "apt install curl\n",
            "apt install git\n",
            "bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)\n",
            "Done\n",
            "Successfully Installed\n",
            "Now you can use Mecab\n",
            "from konlpy.tag import Mecab\n",
            "mecab = Mecab()\n",
            "사용자 사전 추가 방법 : https://bit.ly/3k0ZH53\n",
            "NameError: name 'Tagger' is not defined 오류 발생 시 런타임을 재실행 해주세요\n",
            "블로그에 해결 방법을 남겨주신 tana님 감사합니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IF_-GhMpcVfM"
      },
      "source": [
        "from konlpy.tag import Mecab\n",
        "import operator\n",
        "tokenizer = Mecab()"
      ],
      "execution_count": 67,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aaYnMm8xdzdK"
      },
      "source": [
        "text=\"최강의 슈퍼히어로들이 모였다! 지구의 운명을 건 거대한 전쟁이 시작된다! 지구의 안보가 위협당하는 위기의 상황에서 슈퍼히어로들을 불러모아 세상을 구하는, 일명 어벤져스 작전. 에너지원 테서랙트를 이용한 적의 등장으로 인류가 위험에 처하자 국제평화유지기구인 쉴드의 국장 닉 퓨리는 어벤져스 작전을 위해 전 세계에 흩어져 있던 슈퍼히어로들을 찾아나선다. 아이언맨부터 토르, 헐크, 캡틴 아메리카는 물론, 쉴드의 요원인 블랙 위도우, 호크아이까지, 최고의 슈퍼히어로들이 어벤져스의 멤버로 모이게 되지만, 각기 개성이 강한 이들의 만남은 예상치 못한 방향으로 흘러가는데… 지구의 운명을 건 거대한 전쟁 앞에 어벤져스 작전은 성공할 수 있을까?\""
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_9uP6cPCestY",
        "outputId": "3451f18d-e22b-4f3d-a171-2ad558489260",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(tokenizer.morphs(text))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['최강', '의', '슈퍼', '히어로', '들', '이', '모였', '다', '!', '지구', '의', '운명', '을', '건', '거대', '한', '전쟁', '이', '시작', '된다', '!', '지구', '의', '안보', '가', '위협', '당하', '는', '위기', '의', '상황', '에서', '슈퍼', '히어로', '들', '을', '불러', '모아', '세상', '을', '구하', '는', ',', '일', '명', '어벤져스', '작전', '.', '에너지원', '테', '서', '랙', '트', '를', '이용', '한', '적', '의', '등장', '으로', '인류', '가', '위험', '에', '처하', '자', '국제', '평화', '유지', '기구', '인', '쉴드', '의', '국장', '닉', '퓨리', '는', '어벤져스', '작전', '을', '위해', '전', '세계', '에', '흩어져', '있', '던', '슈퍼', '히어로', '들', '을', '찾', '아', '나선다', '.', '아이언맨', '부터', '토르', ',', '헐크', ',', '캡틴', '아메리카', '는', '물론', ',', '쉴드', '의', '요원', '인', '블랙', '위', '도우', ',', '호크아이', '까지', ',', '최고', '의', '슈퍼', '히어로', '들', '이', '어벤져스', '의', '멤버', '로', '모이', '게', '되', '지만', ',', '각기', '개성', '이', '강한', '이', '들', '의', '만남', '은', '예상', '치', '못한', '방향', '으로', '흘러가', '는데', '…', '지구', '의', '운명', '을', '건', '거대', '한', '전쟁', '앞', '에', '어벤져스', '작전', '은', '성공', '할', '수', '있', '을까', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5wBJySBoev7d"
      },
      "source": [
        "stopwords=['의','가','이','은','다','들','을','는','인','위해','과','던','도','를','로','게','으로','까지','자','에','을까','는데','치','와','한','하다']"
      ],
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3akksDdvf4QH",
        "outputId": "63e00cb0-9be8-496a-e8f9-6f3344642d36",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "tokenized_text = [word for word in tokenizer.morphs(text) if not word in stopwords] # 불용어 제거\n",
        "print(tokenized_text)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['최강', '슈퍼', '히어로', '모였', '!', '지구', '운명', '건', '거대', '전쟁', '시작', '된다', '!', '지구', '안보', '위협', '당하', '위기', '상황', '에서', '슈퍼', '히어로', '불러', '모아', '세상', '구하', ',', '일', '명', '어벤져스', '작전', '.', '에너지원', '테', '서', '랙', '트', '이용', '적', '등장', '인류', '위험', '처하', '국제', '평화', '유지', '기구', '쉴드', '국장', '닉', '퓨리', '어벤져스', '작전', '전', '세계', '흩어져', '있', '슈퍼', '히어로', '찾', '아', '나선다', '.', '아이언맨', '부터', '토르', ',', '헐크', ',', '캡틴', '아메리카', '물론', ',', '쉴드', '요원', '블랙', '위', '도우', ',', '호크아이', ',', '최고', '슈퍼', '히어로', '어벤져스', '멤버', '모이', '되', '지만', ',', '각기', '개성', '강한', '만남', '예상', '못한', '방향', '흘러가', '…', '지구', '운명', '건', '거대', '전쟁', '앞', '어벤져스', '작전', '성공', '할', '수', '있', '?']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HeQZoMEbkuQG"
      },
      "source": [
        "### 2.2 음절 단위 토크나이징 실습"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UTtNysPffaEl"
      },
      "source": [
        "starry_night=['계절이 지나가는 하늘에는',\n",
        "'가을로 가득 차 있습니다.',\n",
        "'나는 아무 걱정도 없이',\n",
        "'가을 속의 별들을 다 헬 듯합니다.',\n",
        "'가슴 속에 하나 둘 새겨지는 별을',\n",
        "'이제 다 못 헤는 것은',\n",
        "'쉬이 아침이 오는 까닭이요,',\n",
        "'내일 밤이 남은 까닭이요,',\n",
        "'아직 나의 청춘이 다하지 않은 까닭입니다.',\n",
        "'별 하나에 추억과',\n",
        "'별 하나에 사랑과',\n",
        "'별 하나에 쓸쓸함과',\n",
        "'별 하나에 동경과',\n",
        "'별 하나에 시와',\n",
        "'별 하나에 어머니, 어머니,',\n",
        "\"어머님, 나는 별 하나에 아름다운 말 한마디씩 불러 봅니다. 소학교 때 책상을 같이 했던 아이들의 이름과, 패, 경, 옥, 이런 이국 소녀들의 이름과, 벌써 아기 어머니 된 계집애들의 이름과, 가난한 이웃 사람들의 이름과, 비둘기, 강아지, 토끼, 노새, 노루, '프랑시스 잠', '라이너 마리아 릴케’ 이런 시인의 이름을 불러 봅니다.\",\n",
        "'이네들은 너무나 멀리 있습니다.',\n",
        "'별이 아스라이 멀듯이.',\n",
        "'어머님,',\n",
        "'그리고 당신은 멀리 북간도에 계십니다.',\n",
        "'나는 무엇인지 그리워',\n",
        "'이 많은 별빛이 내린 언덕 위에',\n",
        "'내 이름자를 써 보고',\n",
        "'흙으로 덮어 버리었습니다.',\n",
        "'딴은 밤을 새워 우는 벌레는',\n",
        "'부끄러운 이름을 슬퍼하는 까닭입니다.',\n",
        "'그러나 겨울이 지나고 나의 별에도 봄이 오면',\n",
        "'무덤 위에 파란 잔디가 피어나듯이',\n",
        "'내 이름자 묻힌 언덕 위에도',\n",
        "'자랑처럼 풀이 무성할 거외다.',]"
      ],
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjoJFnjNhwEG"
      },
      "source": [
        "tokens=[]\n",
        "for sentence in starry_night:\n",
        "    tokenezied_text = [token for token in sentence] \n",
        "    tokens.extend(tokenezied_text)"
      ],
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9oSKy9YLaWU0",
        "outputId": "26ece9cf-a06b-4951-b2d3-57a612cf4a01",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "print(tokens)"
      ],
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['계', '절', '이', ' ', '지', '나', '가', '는', ' ', '하', '늘', '에', '는', '가', '을', '로', ' ', '가', '득', ' ', '차', ' ', '있', '습', '니', '다', '.', '나', '는', ' ', '아', '무', ' ', '걱', '정', '도', ' ', '없', '이', '가', '을', ' ', '속', '의', ' ', '별', '들', '을', ' ', '다', ' ', '헬', ' ', '듯', '합', '니', '다', '.', '가', '슴', ' ', '속', '에', ' ', '하', '나', ' ', '둘', ' ', '새', '겨', '지', '는', ' ', '별', '을', '이', '제', ' ', '다', ' ', '못', ' ', '헤', '는', ' ', '것', '은', '쉬', '이', ' ', '아', '침', '이', ' ', '오', '는', ' ', '까', '닭', '이', '요', ',', '내', '일', ' ', '밤', '이', ' ', '남', '은', ' ', '까', '닭', '이', '요', ',', '아', '직', ' ', '나', '의', ' ', '청', '춘', '이', ' ', '다', '하', '지', ' ', '않', '은', ' ', '까', '닭', '입', '니', '다', '.', '별', ' ', '하', '나', '에', ' ', '추', '억', '과', '별', ' ', '하', '나', '에', ' ', '사', '랑', '과', '별', ' ', '하', '나', '에', ' ', '쓸', '쓸', '함', '과', '별', ' ', '하', '나', '에', ' ', '동', '경', '과', '별', ' ', '하', '나', '에', ' ', '시', '와', '별', ' ', '하', '나', '에', ' ', '어', '머', '니', ',', ' ', '어', '머', '니', ',', '어', '머', '님', ',', ' ', '나', '는', ' ', '별', ' ', '하', '나', '에', ' ', '아', '름', '다', '운', ' ', '말', ' ', '한', '마', '디', '씩', ' ', '불', '러', ' ', '봅', '니', '다', '.', ' ', '소', '학', '교', ' ', '때', ' ', '책', '상', '을', ' ', '같', '이', ' ', '했', '던', ' ', '아', '이', '들', '의', ' ', '이', '름', '과', ',', ' ', '패', ',', ' ', '경', ',', ' ', '옥', ',', ' ', '이', '런', ' ', '이', '국', ' ', '소', '녀', '들', '의', ' ', '이', '름', '과', ',', ' ', '벌', '써', ' ', '아', '기', ' ', '어', '머', '니', ' ', '된', ' ', '계', '집', '애', '들', '의', ' ', '이', '름', '과', ',', ' ', '가', '난', '한', ' ', '이', '웃', ' ', '사', '람', '들', '의', ' ', '이', '름', '과', ',', ' ', '비', '둘', '기', ',', ' ', '강', '아', '지', ',', ' ', '토', '끼', ',', ' ', '노', '새', ',', ' ', '노', '루', ',', ' ', \"'\", '프', '랑', '시', '스', ' ', '잠', \"'\", ',', ' ', \"'\", '라', '이', '너', ' ', '마', '리', '아', ' ', '릴', '케', '’', ' ', '이', '런', ' ', '시', '인', '의', ' ', '이', '름', '을', ' ', '불', '러', ' ', '봅', '니', '다', '.', '이', '네', '들', '은', ' ', '너', '무', '나', ' ', '멀', '리', ' ', '있', '습', '니', '다', '.', '별', '이', ' ', '아', '스', '라', '이', ' ', '멀', '듯', '이', '.', '어', '머', '님', ',', '그', '리', '고', ' ', '당', '신', '은', ' ', '멀', '리', ' ', '북', '간', '도', '에', ' ', '계', '십', '니', '다', '.', '나', '는', ' ', '무', '엇', '인', '지', ' ', '그', '리', '워', '이', ' ', '많', '은', ' ', '별', '빛', '이', ' ', '내', '린', ' ', '언', '덕', ' ', '위', '에', '내', ' ', '이', '름', '자', '를', ' ', '써', ' ', '보', '고', '흙', '으', '로', ' ', '덮', '어', ' ', '버', '리', '었', '습', '니', '다', '.', '딴', '은', ' ', '밤', '을', ' ', '새', '워', ' ', '우', '는', ' ', '벌', '레', '는', '부', '끄', '러', '운', ' ', '이', '름', '을', ' ', '슬', '퍼', '하', '는', ' ', '까', '닭', '입', '니', '다', '.', '그', '러', '나', ' ', '겨', '울', '이', ' ', '지', '나', '고', ' ', '나', '의', ' ', '별', '에', '도', ' ', '봄', '이', ' ', '오', '면', '무', '덤', ' ', '위', '에', ' ', '파', '란', ' ', '잔', '디', '가', ' ', '피', '어', '나', '듯', '이', '내', ' ', '이', '름', '자', ' ', '묻', '힌', ' ', '언', '덕', ' ', '위', '에', '도', '자', '랑', '처', '럼', ' ', '풀', '이', ' ', '무', '성', '할', ' ', '거', '외', '다', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uQME2eaoooVS"
      },
      "source": [
        "## 빈칸완성 과제 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZSdZp0mfiBLQ",
        "outputId": "d9ad4ebf-e258-4e95-9e2f-86d3851abe3d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "source": [
        "from collections import Counter\n",
        "vocab_dict={}\n",
        "words = []\n",
        "for token in tokens:\n",
        "  ##TODO##\n",
        "  '''\n",
        "  vocab_dict에 token을 key로 빈도수를 value로 채워넣으세요.\n",
        "  예시) vocab_dict={\"나\":3,\"그\":5,\"어\":3,...}\n",
        "  '''\n",
        "  words.append(token)\n",
        "  vocab_dict = Counter(words)\n",
        "print(vocab_dict)\n",
        "  ##TODO##"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Counter({' ': 138, '이': 34, ',': 19, '나': 18, '에': 14, '다': 14, '니': 12, '별': 12, '는': 11, '하': 11, '.': 11, '아': 9, '름': 9, '을': 8, '의': 8, '과': 8, '가': 7, '은': 7, '어': 7, '지': 6, '들': 6, '리': 6, '무': 5, '머': 5, '도': 4, '까': 4, '닭': 4, '내': 4, '러': 4, '계': 3, '습': 3, '듯': 3, '새': 3, '랑': 3, '시': 3, \"'\": 3, '멀': 3, '그': 3, '고': 3, '위': 3, '자': 3, '로': 2, '있': 2, '속': 2, '둘': 2, '겨': 2, '오': 2, '요': 2, '밤': 2, '입': 2, '사': 2, '쓸': 2, '경': 2, '님': 2, '운': 2, '한': 2, '마': 2, '디': 2, '불': 2, '봅': 2, '소': 2, '런': 2, '벌': 2, '써': 2, '기': 2, '노': 2, '스': 2, '라': 2, '너': 2, '인': 2, '워': 2, '언': 2, '덕': 2, '절': 1, '늘': 1, '득': 1, '차': 1, '걱': 1, '정': 1, '없': 1, '헬': 1, '합': 1, '슴': 1, '제': 1, '못': 1, '헤': 1, '것': 1, '쉬': 1, '침': 1, '일': 1, '남': 1, '직': 1, '청': 1, '춘': 1, '않': 1, '추': 1, '억': 1, '함': 1, '동': 1, '와': 1, '말': 1, '씩': 1, '학': 1, '교': 1, '때': 1, '책': 1, '상': 1, '같': 1, '했': 1, '던': 1, '패': 1, '옥': 1, '국': 1, '녀': 1, '된': 1, '집': 1, '애': 1, '난': 1, '웃': 1, '람': 1, '비': 1, '강': 1, '토': 1, '끼': 1, '루': 1, '프': 1, '잠': 1, '릴': 1, '케': 1, '’': 1, '네': 1, '당': 1, '신': 1, '북': 1, '간': 1, '십': 1, '엇': 1, '많': 1, '빛': 1, '린': 1, '를': 1, '보': 1, '흙': 1, '으': 1, '덮': 1, '버': 1, '었': 1, '딴': 1, '우': 1, '레': 1, '부': 1, '끄': 1, '슬': 1, '퍼': 1, '울': 1, '봄': 1, '면': 1, '덤': 1, '파': 1, '란': 1, '잔': 1, '피': 1, '묻': 1, '힌': 1, '처': 1, '럼': 1, '풀': 1, '성': 1, '할': 1, '거': 1, '외': 1})\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DHUDU4PoiOt_"
      },
      "source": [
        "sorted_vocab = sorted(vocab_dict.items(), key=operator.itemgetter(1),reverse=True)"
      ],
      "execution_count": 76,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0pb-FfJmjoqz"
      },
      "source": [
        "vocab=[]\n",
        "for token,freq in sorted_vocab:\n",
        "  ##TODO##\n",
        "  '''\n",
        "  정렬된 sorted_vocab에서 빈도수가 2 이상인 token을 vocab에 append하여 vocab을 완성시키세요.\n",
        "  '''\n",
        "  if freq >= 2:\n",
        "    vocab.append(token)\n",
        "  ##TODO##\n",
        "  "
      ],
      "execution_count": 77,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "35WIxjLZkJd4"
      },
      "source": [
        "answer=[' ','이',',','나','에','다','니','별','는', '하', '.', '아', '름', '을', '의', '과', '가', '은', '어', '지', '들', '리', '무', '머', '도', '까', '닭', '내', '러', '계', '습', '듯', '새', '랑', '시', \"'\", '멀', '그', '고', '위', '자', '로', '있', '속', '둘', '겨', '오', '요', '밤', '입', '사', '쓸', '경', '님', '운', '한', '마', '디', '불', '봅', '소', '런', '벌', '써', '기', '노', '스', '라', '너', '인', '워', '언', '덕']"
      ],
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zX1zCJNRiO5k"
      },
      "source": [
        "assert vocab==answer"
      ],
      "execution_count": 79,
      "outputs": []
    }
  ]
}