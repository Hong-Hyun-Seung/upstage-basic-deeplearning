{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "1012_MRC Mission 3 - Sparse & Dense Passage Retrieval.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3.9.6 64-bit ('mrc2': conda)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "toc": {
      "base_numbering": 1,
      "nav_menu": {},
      "number_sections": false,
      "sideBar": true,
      "skip_h1_title": false,
      "title_cell": "Table of Contents",
      "title_sidebar": "Contents",
      "toc_cell": false,
      "toc_position": {
        "height": "calc(100% - 180px)",
        "left": "10px",
        "top": "150px",
        "width": "439.071px"
      },
      "toc_section_display": true,
      "toc_window_display": false
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "1b16d8e4c2d74aab9fdda9ae60c21441": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_58ca9dbe05d149fcb73677736541c1ce",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_92cbaf4e42694aca93e327941b1c9422",
              "IPY_MODEL_e4c5ce6351014015aa41d8a43fdca7d8",
              "IPY_MODEL_9407250e75c14524be3fa222b02c4f74"
            ]
          }
        },
        "58ca9dbe05d149fcb73677736541c1ce": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "92cbaf4e42694aca93e327941b1c9422": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_e38d794604bb409bb4d41a5bfef5eb61",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0a78e445530c4d93a2ccce5bcda351da"
          }
        },
        "e4c5ce6351014015aa41d8a43fdca7d8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_3fe1fbff472c435c94c25c1736081373",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 2,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 2,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_430873d31e5c4770afd48183c1a8f1de"
          }
        },
        "9407250e75c14524be3fa222b02c4f74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ad885d798e64e35ae6705412494a52e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 2/2 [00:00&lt;00:00, 36.73it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_be78ee5fbd55487fb3dd0da23adbc154"
          }
        },
        "e38d794604bb409bb4d41a5bfef5eb61": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0a78e445530c4d93a2ccce5bcda351da": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3fe1fbff472c435c94c25c1736081373": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "430873d31e5c4770afd48183c1a8f1de": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ad885d798e64e35ae6705412494a52e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "be78ee5fbd55487fb3dd0da23adbc154": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    },
    "interpreter": {
      "hash": "e6a65b5bf72b320117a5cfd505c5a1e2290f30898d5727c674807c535145cbf6"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Hong-Hyun-Seung/upstage-basic-deeplearning/blob/main/1012_MRC_Mission_3_Sparse_%26_Dense_Passage_Retrieval_ipynb%EC%9D%98_%EC%82%AC%EB%B3%B8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WjDdziEN_VCt"
      },
      "source": [
        "# Passage Retrieval 구현하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jm9gQPjOWKki"
      },
      "source": [
        "이번 과제에서는 3강에서 배운 **Sparse Passage Retrieval** 과 4강에서 배운 **Dense Passage Retrieval (DPR)** 을 구현해봅니다. \n",
        "\n",
        "Passage Retrieval 을 다시 복습해보면,\n",
        "1. Query와 Passage 를 임베딩 시킨 후\n",
        "2. 임베딩된 벡터들에 각각 dot product를 수행하여 유사도를 구한 후에\n",
        "3. 유사도가 가장 높은 passage 들을 검색 대상으로 합니다.   \n",
        "\n",
        "이 때 임베딩 시키는 방법에서 Sparse 와 Dense 가 나누어진 점, 다들 기억하시죠?\n",
        "차근차근 구현해본 후, 전체 Wikipedia 에 대해서도 작업해봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ug7dthenVCR"
      },
      "source": [
        "```\n",
        "🛠 Setup을 하는 부분입니다. 이전 과제에서 반복되는 부분이기 때문에 무지성 실행 하셔도 좋습니다.\n",
        "💻 실습 코드입니다. 따라가면서 코드를 이해해보세요.\n",
        "❓ 과제입니다. 주어진 질문과 요구사항에 맞춰서 직접 코드를 짜보세요.\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HKIvUE3FcdK6"
      },
      "source": [
        "## 🛠 초기설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1NWluWk3_VCu"
      },
      "source": [
        "### 🛠 Requirements"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eGqFS4EEBF_Z"
      },
      "source": [
        "!pip install tqdm==4.48.0 -q\n",
        "!pip install datasets==1.4.1 -q\n",
        "!pip install transformers==4.5.0 -q"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xHf4ReA9dzyp"
      },
      "source": [
        "### 🛠 난수 고정 및 버전 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T08:06:13.948236Z",
          "start_time": "2021-09-15T08:06:12.672812Z"
        },
        "id": "fNEhsdR6hM-6"
      },
      "source": [
        "import json\n",
        "import random\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm, trange\n",
        "from pprint import pprint\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "import torch.nn.functional as F\n",
        "\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoTokenizer,\n",
        "    BertModel, BertPreTrainedModel,\n",
        "    AdamW, get_linear_schedule_with_warmup,\n",
        "    TrainingArguments,\n",
        ")"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T08:06:13.978267Z",
          "start_time": "2021-09-15T08:06:13.951238Z"
        },
        "id": "sSyEXp19d0L1"
      },
      "source": [
        "# 난수 고정\n",
        "def set_seed(random_seed):\n",
        "    torch.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed(random_seed)\n",
        "    torch.cuda.manual_seed_all(random_seed)  # if use multi-GPU\n",
        "    random.seed(random_seed)\n",
        "    np.random.seed(random_seed)\n",
        "    \n",
        "set_seed(42) # magic number :)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T08:06:14.023236Z",
          "start_time": "2021-09-15T08:06:13.979238Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jsayd5Ite-KY",
        "outputId": "08439471-de33-4d3d-cc4a-3d455494b0ad"
      },
      "source": [
        "print (\"PyTorch version:[%s].\"% (torch.__version__))\n",
        "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "print (\"device:[%s].\"%(device))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "PyTorch version:[1.9.0+cu111].\n",
            "device:[cuda:0].\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CYUkp06Y_VCv"
      },
      "source": [
        "### 🛠 데이터셋 로딩\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KMrZa4uql_nx"
      },
      "source": [
        "KorQuAD 의 train 데이터를 학습 데이터로 활용"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:52:46.968793Z",
          "start_time": "2021-09-15T06:52:28.974382Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4IUxepuj_VCv",
        "outputId": "0be0a024-f6eb-4226-dbd4-c8ea69129719"
      },
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "dataset = load_dataset(\"squad_kor_v1\")\n",
        "print(\"how dataset looks like\")\n",
        "print(dataset)\n",
        "print(\"how dataset[0] looks like\")\n",
        "print(dataset['train'][0])\n",
        "corpus = list(set([example[\"context\"] for example in dataset[\"train\"]]))\n",
        "print(f\"총 {len(corpus)}개의 지문이 있습니다.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset squad_kor_v1 (/root/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/31982418accc53b059af090befa81e68880acc667ca5405d30ce6fa7910950a7)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "how dataset looks like\n",
            "DatasetDict({\n",
            "    train: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 60407\n",
            "    })\n",
            "    validation: Dataset({\n",
            "        features: ['id', 'title', 'context', 'question', 'answers'],\n",
            "        num_rows: 5774\n",
            "    })\n",
            "})\n",
            "how dataset[0] looks like\n",
            "{'answers': {'answer_start': [54], 'text': ['교향곡']}, 'context': '1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.', 'id': '6566495-0-0', 'question': '바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?', 'title': '파우스트_서곡'}\n",
            "총 9606개의 지문이 있습니다.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lJtECqpB_VCx"
      },
      "source": [
        "### 🛠 토크나이저 준비 - Huggingface 제공 tokenizer 이용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X0Fu2WaqpUB8"
      },
      "source": [
        "BERT 를 encoder 로 사용하므로, KLUE에서 제공하는 `klue/bert-base` tokenizer 를 활용해봅시다. 다른 pretrained 모델을 사용하고 싶으시다면, `model_checkpoint`를 바꿔보세요 !"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:52:56.152836Z",
          "start_time": "2021-09-15T06:52:46.970795Z"
        },
        "id": "AoB8BHGDmVIK"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "model_checkpoint = \"klue/bert-base\"\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X48czRQwcxPu"
      },
      "source": [
        "불러온 Tokenzier가 잘 작동하는지 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "an1FiJ2hxbA_",
        "outputId": "af7172c7-af76-486a-dfa5-e4acfafe6835"
      },
      "source": [
        "dataset[\"train\"]"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Dataset({\n",
              "    features: ['id', 'title', 'context', 'question', 'answers'],\n",
              "    num_rows: 60407\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mB1e9cS3xTfv",
        "outputId": "52479611-79f7-4b1a-c2f7-ef09ac8e40e1"
      },
      "source": [
        "dataset[\"train\"][0]"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answers': {'answer_start': [54], 'text': ['교향곡']},\n",
              " 'context': '1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. 이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 걲은 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 완성과 동시에 그는 이 서곡(1악장)을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. 결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 의견도 있다.',\n",
              " 'id': '6566495-0-0',\n",
              " 'question': '바그너는 괴테의 파우스트를 읽고 무엇을 쓰고자 했는가?',\n",
              " 'title': '파우스트_서곡'}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:52:56.182781Z",
          "start_time": "2021-09-15T06:52:56.153749Z"
        },
        "id": "0U7sn3jsu44O"
      },
      "source": [
        "tokenized_input = tokenizer(\n",
        "    dataset[\"train\"][0][\"context\"],\n",
        "    padding=\"max_length\",\n",
        "    truncation=True\n",
        ")\n",
        "#pprint(tokenizer.decode(tokenized_input[\"input_ids\"]))"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U87R4-skxtZO",
        "outputId": "bd166512-9d8c-4507-a798-fe1c66f75840"
      },
      "source": [
        "tokenized_input"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [2, 13934, 2236, 2440, 27982, 2259, 21310, 2079, 11994, 3791, 2069, 3790, 1508, 2088, 636, 3800, 2170, 3717, 2052, 9001, 8345, 4642, 2200, 3689, 3657, 2079, 19282, 2069, 1363, 2370, 2259, 936, 2069, 554, 2259, 2062, 18, 1504, 4342, 27982, 2259, 13934, 2196, 2440, 2170, 1195, 23260, 6233, 17370, 2113, 2165, 2069, 809, 1, 3706, 2052, 2181, 8642, 2145, 7334, 2170, 4983, 2371, 4007, 1065, 5917, 2386, 2559, 4443, 2138, 4026, 2259, 11994, 3791, 2079, 15864, 2170, 5487, 2371, 4683, 3605, 18, 3819, 5986, 27135, 1376, 2645, 2203, 2292, 2079, 5872, 2200, 5986, 4152, 2252, 22835, 16706, 2052, 5485, 2205, 2259, 17087, 2079, 19282, 29, 2517, 2069, 881, 2088, 652, 2073, 23404, 2069, 1122, 2886, 13964, 16, 3982, 2052, 9944, 21, 2429, 2170, 11994, 3791, 2079, 1258, 2465, 6233, 24294, 1504, 3967, 2170, 4027, 2052, 5121, 3979, 2069, 18274, 21575, 23548, 575, 2073, 5292, 2085, 7251, 2116, 1415, 2062, 18, 3776, 2079, 942, 2286, 2446, 4196, 2079, 3640, 6509, 636, 2079, 4450, 2170, 10329, 1513, 2259, 575, 7925, 4488, 2470, 4006, 2125, 7874, 2075, 1329, 2079, 2116, 4523, 2897, 575, 2052, 3614, 2181, 17087, 2079, 10044, 2120, 2482, 2465, 4196, 2079, 3979, 2069, 1122, 2073, 575, 2069, 1164, 1295, 1513, 2062, 18, 3914, 19282, 8067, 2069, 13934, 2236, 2440, 3797, 4064, 2440, 2170, 5314, 5986, 27135, 7615, 2371, 4381, 21, 2376, 2121, 2069, 1365, 873, 2170, 4967, 2371, 2062, 18, 3819, 3967, 2079, 4976, 2145, 4213, 2170, 636, 2259, 1504, 1258, 2465, 12, 21, 2376, 2121, 13, 1498, 5986, 4152, 2252, 2079, 16385, 27135, 5485, 2085, 6237, 2178, 2299, 2118, 3864, 2205, 2507, 4381, 16, 4539, 2259, 6268, 2118, 2259, 1380, 2886, 2062, 18, 3983, 16087, 2073, 24, 2440, 1121, 2052, 3625, 1943, 2170, 9605, 2906, 27135, 5485, 2496, 2359, 2088, 17807, 2119, 4046, 6028, 3683, 16, 3719, 2170, 4311, 8095, 2496, 2088, 1041, 2886, 2062, 18, 636, 3734, 2170, 636, 2259, 1028, 2614, 2225, 2522, 14231, 2205, 2259, 8445, 2179, 2069, 4976, 19521, 1763, 2016, 2052, 2190, 6509, 7615, 2205, 2259, 886, 12100, 2470, 3641, 2069, 5755, 13964, 16, 3637, 9064, 3799, 2052, 1504, 595, 2069, 1515, 2318, 1891, 575, 2052, 5215, 1889, 2259, 4192, 2119, 1513, 2062, 18, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]}"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KyJqZWGfxyeW",
        "outputId": "ec3c7ff1-59dd-4654-d3c9-514bacf8f0f4"
      },
      "source": [
        "pprint(tokenizer.decode(tokenized_input[\"input_ids\"]))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "('[CLS] 1839년 바그너는 괴테의 파우스트을 처음 읽고 그 내용에 마음이 끌려 이를 소재로 해서 하나의 교향곡을 쓰려는 뜻을 갖는다. '\n",
            " '이 시기 바그너는 1838년에 빛 독촉으로 산전수전을 다 [UNK] 상황이라 좌절과 실망에 가득했으며 메피스토펠레스를 만나는 파우스트의 '\n",
            " '심경에 공감했다고 한다. 또한 파리에서 아브네크의 지휘로 파리 음악원 관현악단이 연주하는 베토벤의 교향곡 9번을 듣고 깊은 감명을 '\n",
            " '받았는데, 이것이 이듬해 1월에 파우스트의 서곡으로 쓰여진 이 작품에 조금이라도 영향을 끼쳤으리라는 것은 의심할 여지가 없다. 여기의 '\n",
            " '라단조 조성의 경우에도 그의 전기에 적혀 있는 것처럼 단순한 정신적 피로나 실의가 반영된 것이 아니라 베토벤의 합창교향곡 조성의 영향을 '\n",
            " '받은 것을 볼 수 있다. 그렇게 교향곡 작곡을 1839년부터 40년에 걸쳐 파리에서 착수했으나 1악장을 쓴 뒤에 중단했다. 또한 작품의 '\n",
            " '완성과 동시에 그는 이 서곡 ( 1악장 ) 을 파리 음악원의 연주회에서 연주할 파트보까지 준비하였으나, 실제로는 이루어지지는 않았다. '\n",
            " '결국 초연은 4년 반이 지난 후에 드레스덴에서 연주되었고 재연도 이루어졌지만, 이후에 그대로 방치되고 말았다. 그 사이에 그는 리엔치와 '\n",
            " '방황하는 네덜란드인을 완성하고 탄호이저에도 착수하는 등 분주한 시간을 보냈는데, 그런 바쁜 생활이 이 곡을 잊게 한 것이 아닌가 하는 '\n",
            " '의견도 있다. [SEP] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
            " '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
            " '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
            " '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
            " '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
            " '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
            " '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
            " '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
            " '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
            " '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
            " '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
            " '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] '\n",
            " '[PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD] [PAD]')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZGPpy1Hpd_7m"
      },
      "source": [
        "## 💻 Ⅰ. Sparse Retriever 실습\n",
        "첫 번째로 TF-IDF 를 통해 임베딩 벡터를 만들어봅시다. 이 모듈은 직접 구현할 필요 없이 `sklearn.feature_extract.text` 에서 구현된 것을 사용합시다!\n",
        "\n",
        "더 간단하게 임베딩 벡터를 구할 수 있습니다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UCeRbHPvh8UB"
      },
      "source": [
        "### 💻 1. TF-IDF 학습하기\n",
        "TF-IDF 사용법은 sklearn 홈페이지에서 확인할 수 있습니다. 제공된 링크를 읽어보시면, 아래에 작성된 코드를 쉽게 이해하실 수 있을 거에요.\n",
        "\n",
        "\n",
        "*   [TF-IDF 공식 홈페이지](https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html)\n",
        "*   [TF-IDF 사용 예시](https://wikidocs.net/31698)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:52:56.197781Z",
          "start_time": "2021-09-15T06:52:56.183749Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSQWisY2fUgV",
        "outputId": "c8d4f0be-e01d-4983-aad9-a6cdbe145acb"
      },
      "source": [
        "# Huggingface의 Tokenizer를 사용하셔도 좋고\n",
        "tokenizer_func = lambda x: tokenizer.tokenize(x)\n",
        "\n",
        "# 혹은 단순 띄어쓰기 기준으로 Tokenize 하셔도 좋습니다.\n",
        "# tokenizer_func = lambda x: x.split(' ')\n",
        "\n",
        "# 어떻게 Tokenize 되었는지 확인해봅시다.\n",
        "print(f\"{'-'*30} 기존 문장 {'-'*30}\")\n",
        "pprint(corpus[20])\n",
        "print(f\"\\n{'-'*30} Tokenize 된 문장 {'-'*30}\")\n",
        "pprint(\" \".join(tokenizer_func(corpus[20])))"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "------------------------------ 기존 문장 ------------------------------\n",
            "('윤영의 집은 심히 가난하였다 한다. 여자 노비 한명과, 논 몇 마지기가 있었는데 용도에 넉넉치 않아 결국 가산과 전답을 모두 팔았다. '\n",
            " '여름에는 비가 오면 지붕이 심하게 새어서 윤영이 직접 구들을 송곳으로 찔려 물이 흐르게 하여서 겨우 거주했고 장황도서편(章潢圖書篇)을 '\n",
            " '열람했으니 그 부지런하고 노력하는 것이 이와 같았다. 등나무와 칡이 두른 담장 밖에서 길가는 사람이 들어와서 불을 빌리려고 하거늘 '\n",
            " '동행하는 자가 못가게 말리면서 말하기를, “불을 빌리려 가는데 늪으로 들어가는 것은 무엇이냐?”라고 말하였다. 이복 동생인 윤휴는 그를 '\n",
            " '형으로 대우하여 깎듯이 대하였다. 그러나 윤휴가 죽고 그 아들들조차 원지로 유배되면서 그는 직접 밭을 일구고 농업으로 생활하였다.')\n",
            "\n",
            "------------------------------ Tokenize 된 문장 ------------------------------\n",
            "('윤영 ##의 집 ##은 심히 가난 ##하 ##였 ##다 한다 . 여자 노비 한명 ##과 , 논 몇 마지 ##기 ##가 있 ##었 ##는데 '\n",
            " '용도 ##에 넉넉 ##치 않 ##아 결국 가산 ##과 전 ##답 ##을 모두 팔 ##았 ##다 . 여름 ##에 ##는 비 ##가 오 '\n",
            " '##면 지붕 ##이 심하 ##게 새 ##어 ##서 윤영 ##이 직접 구 ##들 ##을 송곳 ##으로 찔 ##려 물 ##이 흐르 ##게 '\n",
            " '하여 ##서 겨우 거주 ##했 ##고 장황 ##도 ##서 ##편 ( 章 [UNK] 圖 書 [UNK] ) 을 열람 ##했 ##으니 그 '\n",
            " '부지런 ##하고 노력 ##하 ##는 것 ##이 이와 같 ##았 ##다 . 등 ##나무 ##와 [UNK] 두른 담장 밖에 ##서 길가 '\n",
            " '##는 사람 ##이 들어와서 불 ##을 빌리 ##려고 하 ##거 ##늘 동행 ##하 ##는 자가 못 ##가 ##게 말리 ##면서 말 '\n",
            " '##하기 ##를 , “ 불 ##을 빌리 ##려 가 ##는데 늪 ##으로 들어가 ##는 것 ##은 무엇 ##이 ##냐 ? ” 라고 말 '\n",
            " '##하 ##였 ##다 . 이복 동생 ##인 윤 ##휴 ##는 그 ##를 형 ##으로 대우 ##하여 깎 ##듯 ##이 대하 ##였 ##다 '\n",
            " '. 그러나 윤 ##휴가 죽 ##고 그 아들 ##들 ##조 ##차 원지 ##로 유배 ##되 ##면서 그 ##는 직접 밭 ##을 일구 ##고 '\n",
            " '농업 ##으로 생활 ##하 ##였 ##다 .')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5LZR8COph2g9"
      },
      "source": [
        "모듈을 활용해서 `fit` 해봅시다. 과정은 어렵지 않습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:53:20.560497Z",
          "start_time": "2021-09-15T06:52:56.198781Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OyQ290Cdd64F",
        "outputId": "620a48c7-966d-45b0-d001-8d17f0d8a231"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "\n",
        "vectorizer = TfidfVectorizer(\n",
        "    tokenizer=tokenizer_func,\n",
        "    ngram_range=(1,2)\n",
        ")\n",
        "vectorizer.fit(corpus)\n",
        "sp_matrix = vectorizer.transform(corpus)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/feature_extraction/text.py:507: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
            "  warnings.warn(\"The parameter 'token_pattern' will not be used\"\n",
            "Token indices sequence length is longer than the specified maximum sequence length for this model (855 > 512). Running this sequence through the model will result in indexing errors\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g4sPODsJ76xm"
      },
      "source": [
        "`Vectorizer`로 임베딩을 시켜주면 (문서의 개수, 단어의 개수) 꼴의 행렬로 변환이 됩니다. 기본적으로 단어의 개수는 지정해주지 않으면 전체 단어의 개수만큼 차원이 지정됩니다. 사용되는 단어의 개수가 너무 많아서 지나치게 행렬이 희소해지면 사용이 불편하기 때문에, 필요하다면 벡터 임베딩 사이즈 또한 지정해줄 수 있습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4nh6x8o9KCP"
      },
      "source": [
        "참고로 결과물이 희소행렬이기 때문에 평소에 사용되는 `numpy.ndarray`가 아닙니다. Scipy 모듈의 csr_matrix를 이용하는데 이는 아래 링크를 참고해주세요\n",
        "+ [scipy.sparse.csr_matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html)\n",
        "+ [Scipy sparse matrix handling](https://lovit.github.io/nlp/machine%20learning/2018/04/09/sparse_mtarix_handling/)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sBuC_c-e9PHF",
        "outputId": "17f89fe8-87c1-4221-9103-dca5eb5fdf1c"
      },
      "source": [
        "type(sp_matrix)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "scipy.sparse.csr.csr_matrix"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:53:20.575499Z",
          "start_time": "2021-09-15T06:53:20.562498Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PxHJP5HHfxFm",
        "outputId": "3aff92dd-935b-4ab8-bf68-5ff3a0d033b2"
      },
      "source": [
        "sp_matrix.shape # (num_passage, num_vocab)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9606, 684272)"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TxSvTRPFiH0Z"
      },
      "source": [
        "첫 번째 문장의 TF-IDF 벡터를 확인해볼까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:53:21.609083Z",
          "start_time": "2021-09-15T06:53:20.577499Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nf0fNy11fzXY",
        "outputId": "18a6e1e0-5745-4cfa-ab91-1e15a4cd0cf9"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "df = pd.DataFrame(\n",
        "    sp_matrix[0].T.todense(),\n",
        "    index=vectorizer.get_feature_names(),\n",
        "    columns=[\"TF-IDF\"]\n",
        ")\n",
        "df = df.sort_values(\"TF-IDF\", ascending=False)\n",
        "print(df.head(10))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           TF-IDF\n",
            "작업       0.134582\n",
            "매진 ##되   0.114383\n",
            "##판 ##매  0.106780\n",
            "l ##p    0.104066\n",
            "음반       0.099344\n",
            "매진       0.098451\n",
            "제작       0.097789\n",
            "좋 ##다    0.092275\n",
            "##위      0.090951\n",
            "##다      0.090121\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IgjN_SF7iM_N"
      },
      "source": [
        "### 💻 2. Query 임베딩하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YEdiT1W78X5y"
      },
      "source": [
        "이제 Query 를 임베딩해봅시다. 아까 사용한 `vectorizer`를 이용하면 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:53:21.624082Z",
          "start_time": "2021-09-15T06:53:21.611084Z"
        },
        "id": "sXSOfYisf5ad"
      },
      "source": [
        "sample_idx = random.choice(range(len(dataset[\"train\"])))\n",
        "\n",
        "query = dataset[\"train\"][sample_idx][\"question\"]\n",
        "ground_truth = dataset[\"train\"][sample_idx][\"context\"]"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:53:21.654082Z",
          "start_time": "2021-09-15T06:53:21.626084Z"
        },
        "id": "dw0T5Drrf658"
      },
      "source": [
        "query_vec = vectorizer.transform([query])"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXpNKTYSia9D"
      },
      "source": [
        "### 💻 3. Dot Product 를 통해 유사도 구하기\n",
        "내적을 통해 주어진 Query 와 전체 Passage 사이의 유사도를 구해봅시다.\n",
        "그리고 값을 내림차순으로 나열하여 높은 점수를 가진 Passage 들을 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:54:25.265288Z",
          "start_time": "2021-09-15T06:54:25.046289Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lLsck2Lyf_Vm",
        "outputId": "3e940842-bc2e-4023-aaa1-cc6645d58468"
      },
      "source": [
        "result = query_vec * sp_matrix.T\n",
        "result.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1, 9606)"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:54:26.190604Z",
          "start_time": "2021-09-15T06:54:26.172592Z"
        },
        "id": "kLRrldUef8Cw"
      },
      "source": [
        "sorted_result = np.argsort(-result.data)\n",
        "doc_scores = result.data[sorted_result]\n",
        "doc_ids = result.indices[sorted_result]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:54:26.555129Z",
          "start_time": "2021-09-15T06:54:26.541098Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kDYgaL3wgBC6",
        "outputId": "bc810b50-e352-4391-da83-cc29b7b4dc88"
      },
      "source": [
        "k = 5\n",
        "doc_scores[:k], doc_ids[:k]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([0.1716712 , 0.15452864, 0.11226982, 0.0875597 , 0.0853972 ]),\n",
              " array([4911, 5056, 1923, 2311, 9509], dtype=int32))"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pin40NMV91-l"
      },
      "source": [
        "잘 뽑았는지 확인해봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:54:27.343209Z",
          "start_time": "2021-09-15T06:54:27.333696Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8e-OSr2tgCGt",
        "outputId": "b018af21-6206-4404-ed18-867515da9686"
      },
      "source": [
        "print(\"[Search query]\\n\", query, \"\\n\")\n",
        "\n",
        "print(\"[Ground truth passage]\")\n",
        "print(ground_truth, \"\\n\")\n",
        "\n",
        "for i in range(k):\n",
        "    print(f\"Top-{i + 1} passage with score {doc_scores[i]:.4f}\")\n",
        "    doc_id = doc_ids[i]\n",
        "    print(corpus[doc_id], \"\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Search query]\n",
            " 고려대학교 교호에 등장하는 몇 사람의 이름이 등장하는가? \n",
            "\n",
            "[Ground truth passage]\n",
            "이처럼 고려대학교 교호에는 입실렌티, 체이홉, 카시코시 코시코, 카를 마르크스까지 모두 네 사람의 이름이 등장한다. 이들은 출생 연대는 서로 다르지만 사회 저항비판 의식이 강했던 인물들이다. 따라서 교호를 만든 사람은 입실렌티, 체이홉, 카시케시 코시코에게 순서에 관계없이 ‘자유’, ‘정의’, ‘진리’라는 교훈(校訓)을 부여해 고대생에게 사회 저항의식을 가져야 함을 역설하고 있다. ‘입실렌티’는 19세기 오스만 투르크에 저항하여 반란을 일으켰던 알렉산드로스 입실란티스의 이름에서 나왔고, ‘체이홉’은 러시아의 작가 안톤 체호프라는 설과 동명의 러시아 혁명가라는 설이 있으며, ‘카시코시 코시코’는 폴란드의 혁명가 타데우시 코시치우슈코로부터 유래한 것이라는 설과 카시코시우스라는 그리스인으로부터 유래하였다는 설이 존재한다. ‘칼마시’는 카를 마르크스다. 다시 말해 고려대학교 교호는 ‘입실렌티, 체이홉, 카시코시 코시코, 칼 마르크스’가 계시는(케시케시) 고려대학교라는 의미를 담고 있다. \n",
            "\n",
            "Top-1 passage with score 0.1717\n",
            "이처럼 고려대학교 교호에는 입실렌티, 체이홉, 카시코시 코시코, 카를 마르크스까지 모두 네 사람의 이름이 등장한다. 이들은 출생 연대는 서로 다르지만 사회 저항비판 의식이 강했던 인물들이다. 따라서 교호를 만든 사람은 입실렌티, 체이홉, 카시케시 코시코에게 순서에 관계없이 ‘자유’, ‘정의’, ‘진리’라는 교훈(校訓)을 부여해 고대생에게 사회 저항의식을 가져야 함을 역설하고 있다. ‘입실렌티’는 19세기 오스만 투르크에 저항하여 반란을 일으켰던 알렉산드로스 입실란티스의 이름에서 나왔고, ‘체이홉’은 러시아의 작가 안톤 체호프라는 설과 동명의 러시아 혁명가라는 설이 있으며, ‘카시코시 코시코’는 폴란드의 혁명가 타데우시 코시치우슈코로부터 유래한 것이라는 설과 카시코시우스라는 그리스인으로부터 유래하였다는 설이 존재한다. ‘칼마시’는 카를 마르크스다. 다시 말해 고려대학교 교호는 ‘입실렌티, 체이홉, 카시코시 코시코, 칼 마르크스’가 계시는(케시케시) 고려대학교라는 의미를 담고 있다. \n",
            "\n",
            "Top-2 passage with score 0.1545\n",
            "정릉캠퍼스는 원래 우석대학교의 의과대학/의과기술초급대학을 제외한 나머지 학과가 있던 캠퍼스였다. 1971년 고려대학교의 우석대학교 인수 이후 2004년까지 고려대학교 병설 보건대학이 이곳에 위치했으나, 2005년 10월 25일 교육인적자원부가 고려대학교와 고려대학교 병설 보건대학의 통합을 승인하면서 고려대학교에 신규 단과대학인 보건과학대학 이 이곳에 신설됐다. 정릉캠퍼스는 정의관, 진리관, 호림관, 학생회관, KU-MAGIC 연구원 등 5개의 건물로 구성된다. 고려대학교 사범대학 부속중학교 및 고려대학교 사범대학 부속고등학교 또한 정릉캠퍼스에 위치하고 있다. 2015년에 고려대학교 보건과학대학 은 안암동 자연계 캠퍼스에 신축한 하나과학관으로 모두 이전하였으며, 이에 따라 2016년부터 정릉캠퍼스는 KU-MAGIC(Medical Applied R&D Global Initiative Center) Project One 의 연구시설로 사용되고 있다. \n",
            "\n",
            "Top-3 passage with score 0.1123\n",
            "어윤대 총장의 재임기간 동안 고려대학교는 2006년 영국 《타임즈》지가 발표한 세계대학순위에서 종합 150위에 오르는 등 많은 성과를 기록하였다. 사회과학·경영, 인문·예술, 자연과학, 생명과학·의학, 공학·기술 분야에서 조사를 시행한 ‘2012 조선일보·QS 아시아대학평가’에서 고려대학교는 경영학, 법학, 행정학, 교육학 등이 포함되는 사회과학 분야에서 아시아 12위를 차지한 바 있다. 한편, 고려대학교 경영대학은 2009년 경영대학 평가 전문기관인 에듀니버설이 전 세계 경영대 학장 1000명을 상대로 한 설문조사에서 ‘추천하고 싶은 대학’ 국내 1위에 올랐으며, 2010년 대한민국 경영대 평가 설문 조사에서 1위를 차지한 데 이어 2012년 UTD 랭킹에서는 86위에 올라 대한민국 대학 중에서 1위를 차지하였다. MBA는 교육과학기술부의 BK21 평가에서 2007년부터 2011년까지 5년 연속으로 1위를 차지하였다. BK21의 후속 사업인 BK21 플러스의 2013년 초기 선정 결과도 사업단 수와 지원 금액에서 서울대학교에 이어 2위를 차지하였으며, 특히 공과대학의 모든 분야가 Bk21 플러스에 선정됐다. 대한민국 경영대학 가운데 AACSB와 EQUIS 두 곳의 인증을 최초로 받은 곳 역시 고려대학교다. 2011년에 신규 임용된 42기 사법연수생 가운데 고려대학교 출신자는 189명으로 서울대학교 다음으로 많았다. 2009년에 치러진 51회 사법시험에서는 고려대학교 법과대학에서 155명의 합격자를 내 가장 많은 합격자를 내기도 하였다. \n",
            "\n",
            "Top-4 passage with score 0.0876\n",
            "후경의 작전은 주효하여 사흘 동안 후경의 병력이 급증한데 비해 내성의 방어군은 빗의 이가 빠지듯 탈주가 잇따랐고, 549년 3월에 군을 지휘하던 양간이 병사함으로써 전세는 후경에게로 기울었다. 내성의 군사나 농성중이던 남녀들도 몸이 붓고 호흡도 곤란해 지는 가운데, 후경은 현무호(玄武湖)의 물을 끌어들여 성에 대한 수공을 펼쳤고, 결국 성은 함락되었다. 마침내 후경이 황제를 알현할 때 무제가 후경에게 말하기를, \"경이 군중에 있은지 오래되었으니, 어찌 수고로움이 없겠는가!\" 하자, 후경은 얼굴에 땀을 흘리며 고개를 들지 못하였다고 한다. 무제가 다시 묻기를, \"경은 어느 주(州)의 사람이며, 감히 여기에 이르렀는데, 처자는 아직 북쪽에 있는가?\" 라고 했다. 후경이 여전히 대답을 못하자, 후경의 옆에 있던 임약(任約)이 대신 대답하기를, \"신 후경의 처자는 고씨(高氏)에게 도륙당하고 오직 이 한몸으로 폐하께 돌아왔습니다.\" 라고 하였다. 무제가 마침내 \"강을 건널 때는 몇 명이 있었는가?\" 라고 묻자 후경은 천 명이라고 대답했고, 다시 \"성을 포위했을 때는 몇 명이었는가?\" 라고 묻자 후경은 10만 명이었다고 대답했으며, 마지막으로 \"그럼 지금은 몇 명이 있는가?\" 라고 묻자 후경은 \"거느리는 땅에서 제 것이 아닌 것은 없습니다.\" 라고 대답했는데, 결국 무제는 더 이상 아무 말도 하지 않았다고 한다. 유폐된 상태에서 식사조차 제대로 공급받지 못하고, 울분 속에 병이 든 황제는 마지막으로 꿀을 달라고 요구했지만 그것마저도 허락되지 못한 채, 실의와 쇠약으로 결국 죽고 말았다. \n",
            "\n",
            "Top-5 passage with score 0.0854\n",
            "하부 구조는 4기의 교각과 2기의 교대로 이루어져 있으며 교각들은 옛 교량처럼 교토 방향에서부터 차례로 제1호 ~ 제4호 순으로 번호가 붙어 있다. 이 중 제1호에서 제3호까지는 교각의 굵기가 4 m, 제4호는 3 m이다. 또한 유효 경간은 교대에서 제1호 교각까지가 50.1 m, 제1호 ~ 제2호 교각과 제2호 ~ 제3호 교각이 82.5 m, 제3호 ~ 제4호 교각이 55.0 m, 끝으로 제4호 교각에서 교대까지가 34.1 m이다. 이 유효 경간의 배치는 제1호 교각과 제2호 교각 사이로 나가타니 강과 국도 제178호선이 지나는 점과, 옛 교량의 교각을 피해 새 교각을 건설해야하는 점, 상부 공작물의 돌출부 가설의 균형 등을 고려한 것이다. 교각의 높이는 제4호 교각의 33.67 m부터 제1호 교각의 36.0 m까지 제각각 다르며, 땅 밑으로는 최대 23.0 m까지 구덩이를 파 다리의 기초로 삼았다. 아마루베 철교는 교각의 높이가 비교적 높기 때문에 지진이 일어났을 때 빠른 복구가 어려우므로 이를 예방하기 위한 내진 설계가 설계의 중심이 되었다. \n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DirOwPFOixwg"
      },
      "source": [
        "Ground Truth 와 동일한 Passage 가 잘 나왔나요? 제법 성능이 나쁘지 않은걸 확인할 수 있네요.   \n",
        "### ❓ 제시된 두 Tokenizer 를 모두 활용해서 결과를 비교해볼까요?\n",
        "위에서 제시된 Hugginface Tokenizer 와 단순 띄어쓰기로 구분된 Tokenizer 는 많은 차이를 불러올까요? 직접 코드로 구현해봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Hl9vDzADcnPu"
      },
      "source": [
        "### ❓ SparseRetrieval 코드를 class로 합쳐봅시다.\n",
        "Sparse Retrieval 을 잘 구현하셨나요? 하지만 코드가 너무 흩어져있어서 다시 재사용하기 많이 어렵겠네요. 이 코드들을 다른 사람들도 잘 활용할 수 있도록 모듈화를 진행해봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34DcdPHglRIr"
      },
      "source": [
        "❗ _Hint_   \n",
        "Scratch 부터 짜는게 많이 어려우신가요?\n",
        "\n",
        "만들어야하는 기능들의 파이프라인을 나열하고 하나씩 모듈화하는 습관을 들이는 것이 좋습니다. 순서대로 생각해볼까요?\n",
        "\n",
        "1. 데이터를 불러옵니다.\n",
        "2. TF-IDF 를 Fitting 한 후 Passage 를 Transform 합니다.\n",
        "3. Query 를 Fitting 한 TF-IDF 를 통해 Transform 합니다.\n",
        "4. Inner dot product 를 이용해 유사도를 구하고, 내림차순을 통해 유사한 Passage 를 Retrieval 합니다.\n",
        "\n",
        "위의 단계를 하나씩 함수로 구현한 후 class로 합치면 훨씬 쉬울 겁니다! 반드시 이 과정을 따르지 않으셔도 됩니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jr-IgCXWGysH"
      },
      "source": [
        "# 화이팅\n",
        "class TfIdfRetrieval:\n",
        "\n",
        "    def __init__(self, tokenize_fn, data_path):\n",
        "\n",
        "        \"\"\"\n",
        "        1. 여기서 Data를 불러올까요.\n",
        "        \"\"\"\n",
        "\n",
        "        pass\n",
        "\n",
        "    def get_sparse_embedding(self):\n",
        "\n",
        "        \"\"\"\n",
        "        2. 여기서 주어진 전체 passage들에 대해 TF-IDF를 .fit 해줍시다.\n",
        "        \"\"\"\n",
        "\n",
        "        pass\n",
        "\n",
        "    def get_relevant_doc(self, query, k=1):\n",
        "\n",
        "        \"\"\"\n",
        "        여기서\n",
        "            3. Query를 받아서 TF-IDF에 Transform 시켜줍니다.\n",
        "            4. 전체 Passage에 대한 유사도를 구한 후 상위 k개의 Passage를 반환합니다.\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N6lvjwZRwa5h"
      },
      "source": [
        "class TfIdfRetrieval:\n",
        "    def __init__(self,\n",
        "        tokenize_fn,\n",
        "        data_path = \"./data/wikipedia_documents.json\"\n",
        "    ):\n",
        "\n",
        "        self.data_path = data_path\n",
        "        with open(data_path, \"r\", encoding=\"utf-8\") as f:\n",
        "            wiki = json.load(f)\n",
        "        self.contexts = list(dict.fromkeys([v[\"text\"] for v in wiki.values()]))\n",
        "\n",
        "        self.tfidfv = TfidfVectorizer(\n",
        "            tokenizer=tokenize_fn,\n",
        "            ngram_range=(1, 2),\n",
        "            max_features=50000,\n",
        "        )\n",
        "\n",
        "    def get_sparse_embedding(self):\n",
        "        print(\"Build Embedding\")\n",
        "        self.passage_embedding = self.tfidfv.fit_transform(self.contexts)\n",
        "\n",
        "    def get_relevant_doc(self, query: str, k=1):\n",
        "        query_vec = self.tfidfv.transform([query])\n",
        "        result = query_vec * self.passage_embedding.T\n",
        "\n",
        "        sorted_result = np.argsort(-result.data)\n",
        "        doc_scores = result.data[sorted_result]\n",
        "        doc_ids = result.indices[sorted_result]\n",
        "        \n",
        "        return doc_scores.tolist()[:k], doc_ids.tolist()[:k]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l_2Vvx8BdzXw"
      },
      "source": [
        "잘 구현하셨나요? 여러분들이 만든 클래스를 아래와 같이 활용하는데 성공하셨다면 마무리된 것입니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:54:39.464565Z",
          "start_time": "2021-09-15T06:54:38.837869Z"
        },
        "id": "-W8Tl7osdyf7"
      },
      "source": [
        "tokenize_fn = lambda x: tokenizer.tokenize(x)\n",
        "retriever = TfIdfRetrieval(tokenize_fn=tokenize_fn, data_path=\"../data/wikipedia_documents.json\")\n",
        "\n",
        "retriever.get_sparse_embedding()\n",
        "query = \"미국의 대통령은 누구인가?\"\n",
        "doc_score, doc_indices = retriever.get_relevant_doc(query, k=3)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IXorfdV1hHGH"
      },
      "source": [
        "print(f\"[Search Query] {query}\")\n",
        "\n",
        "for i, idx in enumerate(doc_indices):\n",
        "    print(f\"Top-{i + 1}th Passage (Index {idx})\")\n",
        "    pprint(retriever.contexts[idx])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHOE4jZqhXRs"
      },
      "source": [
        "직접 만든 코드에 다음과 같은 추가 사항들을 고려해봅시다.   \n",
        "#### ➕추가 과제: 다양한 기능 추가하기\n",
        "+ 현재 코드가 **어떻게 동작하고 있는지** 궁금하지 않으신가요? 가령, 코드가 돌고는 있는데 대체 어떤 메소드를 수행 중인지, 아니면 시간이 얼마나 걸리는지 등 추가적인 정보를 Logger 에 기록하거나 Prompt 에 찍는 방향으로 더 추가해보세요 !\n",
        "+ 위에서 시간을 출력하는 코드를 짜보셨다면, 이제 fitting 시간이 적지 않음을 확인할 수 있었습니다. 그리고 passage 가 자주 변경되는 것이 아니라면, 같은 기법을 사용해서 **매번 fitting 을 하는 것은 아주 비효율적**입니다. 임베딩된 passage를 따로 **저장해두고 불러와서 사용하면** 더 효율적이지 않을까요? 이 임베딩들을 `.bin` 파일로 저장하고, 만약 `.bin` 파일이 있다면 TfidfVectorizer 가 fitting 하지 않고, 이 `.bin` 파일을 불러오는 방향으로 코드를 추가해봅시다.\n",
        "+ 예외 케이스가 있지 않을까요? **query가 `str` 1개가 아니라 2개 이상인 `List[str]`로 주어진 경우에는 어떻게 해야할까요?** 이 상황은 멀리 있지 않고 여러분들이 대회에서 inference 할 때도 필요한 코드입니다. 단순히 반복문을 돌릴 수 있지만, 우리는 행렬곱을 이용하고 있기 때문에 만약 query 가 여러 개면 이 행렬곱의 장점을 이용할 수 있을 것 같습니다.\n",
        "    + 한 개의 query(`str`) 에 대해 유사한 passage 를 구하는 함수와\n",
        "    + 여러 개의 query(`list`) 에 대해 유사한 passage 를 구하는 함수\n",
        "\n",
        "  두 가지를 만들어봅시다. 그리고 `retrieve` 라는 함수를 만들어서 query 가 한 개인지 다수인지 체크한 후 각각의 함수를 사용해서 유사한 passage 를 찾도록 수정해봅시다.\n",
        "+ 또 다른 예외케이스는 `TfidfVectorizer` 에서 생길 수 있습니다. 가령 Passage 에서 한 번도 보지 못한 단어로만 구성된 query 를 입력했다면, TF-IDF 의 특성상 이 단어는 0 으로만 임베딩될 것입니다. 전체 벡터가 0이 되면 어떻게 처리해야할까요? `assert` 를 활용해보세요!\n",
        "+ 이 메소드는 어떤 parameters를 받아오고 어떤 기능을 하는지 docstring을 추가해봅시다.\n",
        "\n",
        "\n",
        "요구사항이 너무 많나요? 원래 인생이 그렇습니다.\n",
        "\n",
        "_Sparse Retrieval 과제는 두 가지 (기존과 추가 과제) 모두 예시 코드가 금요일 (10/15)제공됩니다._"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zpoTleVJjp5x"
      },
      "source": [
        "## 💻 Ⅱ. Dense Retriever (BERT) 학습 시키기\n",
        "\n",
        "이번에는 BERT 를 불러오고 학습시키는 과정을 거쳐봅시다. 시작하기 전에 어떤 과정을 거쳐야할 지 생각해봅시다.\n",
        "1. 데이터셋 준비\n",
        "2. 모델 준비\n",
        "3. 학습하기 \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HmAIDfEbeENm"
      },
      "source": [
        "### 💻 1. 데이터셋 준비하기\n",
        "위에서 불러온 `datasets`를 이용해 데이터를 불러왔습니다. 하지만 이번 과제에서 passage encoder 가 학습되는 방식은 주어진 query/question에 적합한 passage 를 찾아오는 과정이 필요한데, 이 때 올바른 데이터만 이용해서 학습하는 것이 아니라, 올바르지 않은 passage 또한 학습해보는 과정을 거쳐야합니다. 이를 in-batch negative 라고 부르는데 관련된 내용은 기계독해 강의와 아래 논문을 참고해보세요.\n",
        "+ [Dense Passage Retrieval](https://arxiv.org/abs/2004.04906)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-bKwkxTpoje"
      },
      "source": [
        "#### 💻 Training Dataset 준비하기 (question, passage pairs)\n",
        "\n",
        "실습 시간을 단축시키기 위해 일부 데이터만 활용해봅시다.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:56:49.543616Z",
          "start_time": "2021-09-15T06:56:49.543616Z"
        },
        "id": "E_FQ1kcazxge"
      },
      "source": [
        "sample_idx = np.random.choice(range(len(dataset[\"train\"])), 20)\n",
        "training_dataset = dataset[\"train\"][sample_idx]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALNnnBJTxeU4"
      },
      "source": [
        "#### 💻 Negative sampling 을 위한 negative sample 들을 샘플링\n",
        "\n",
        "주어진 query/question 에 해당하지 않는 지문들을 뽑아서 훈련데이터로 넣어줍시다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:56:49.545616Z",
          "start_time": "2021-09-15T06:56:49.545616Z"
        },
        "id": "LPomXJ1Afc6l"
      },
      "source": [
        "# In-batch Negatvie로 사용할 데이터 생성\n",
        "num_neg = 2\n",
        "\n",
        "corpus = np.array(corpus)\n",
        "p_with_neg = []\n",
        "\n",
        "for c in training_dataset[\"context\"]:\n",
        "    \n",
        "    while True:\n",
        "        neg_idxs = np.random.randint(len(corpus), size=num_neg)\n",
        "\n",
        "        if not c in corpus[neg_idxs]:\n",
        "            p_neg = corpus[neg_idxs]\n",
        "\n",
        "            p_with_neg.append(c)\n",
        "            p_with_neg.extend(p_neg)\n",
        "            break"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ir_hYkQ5fBro"
      },
      "source": [
        "주어진 질문에 알맞는 지문과 올바르지 않는 지문을 모두 살펴봅시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T06:56:49.546616Z",
          "start_time": "2021-09-15T06:56:49.546616Z"
        },
        "id": "wbGW7PRJ7Yv5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7bc3b3ac-5f88-4c0f-fa07-76bf21d9b148"
      },
      "source": [
        "print(\"[Query Given]\")\n",
        "pprint(training_dataset[\"question\"][0])\n",
        "\n",
        "print(\"\\n[Positive context]\")\n",
        "pprint(p_with_neg[0])\n",
        "\n",
        "print(\"\\n[Negative context]\")\n",
        "pprint(p_with_neg[1])\n",
        "pprint(p_with_neg[2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Query Given]\n",
            "'문제는 나랏법 자체보다는 법을 적용하고 옹호하는 데 있었다고 묘사한 사학자는?'\n",
            "\n",
            "[Positive context]\n",
            "('전원 공동체, 특히 그 중에서도 잉글랜드 동남부는 농노제의 작동과 지역 장원 재판소의 세금 징수를 불만스러워했다. 특히 재판소를 운영하는 '\n",
            " '영주들이 곧 원성을 사는 노동 조례나 왕실에서 제정한 법의 현장 집행자로 기능하는 경우가 잦았기 때문에 불만은 가중되었다. 촌락의 엘리트 '\n",
            " '계층 다수는 지방정부의 역할을 맡는 것을 거부했고, 재판소의 활동을 방해하기 시작했다. 재판소에 의해 몰수된 가축들은 그 주인들에 의해 '\n",
            " '‘해방’되었고, 법관들은 폭행을 당했다. 일부는 전통적인 법을 존중하나 런던에서 내려오는 증오받는 중앙 법률에서는 분리된, 독립적인 촌락 '\n",
            " '공동체의 탄생을 지지하기 시작했다. 사학자 미리 루빈은 이 상황을, “문제는 나랏법 그 자체라기보다, 그 법을 적용하고 옹호하는 데 '\n",
            " '있었다”고 묘사한다.')\n",
            "\n",
            "[Negative context]\n",
            "'9월 26일 바예지드는 전투 직전 라호보의 오스만 군 포로들을 프랑스인들이 죽인것에 대한 보복으로 3,000명에서 10,000명에 달하는 포로들을 죽일 것을 명한다. 그는 또 그가 압도적인 승리를 거두었음에도 불구하고 전투 초반에 많은 병사들을 잃은 것에 대하여 분노하였다. 그는 어린 포로들을 자신의 군대에 편입시켰다. 고향으로 돌아가는 와중에 많은 고생을 하지만 결국 돌아간 이들도 있었다. 지기스문트는 니콜라 고르잔스키와 실리의 헤르만의 도움으로 도망칠 수 있었다. 그는 베네치아 배를 타 흑해, 에게 해, 그리고 지중해를 통해 해로로 고향으로 돌아가는 길을 택했고 이 와중에 왈라키아인들의 믿을 수 없는 성품을 알아차린다. 샤를 6세에게 패배소식이 크리스마스에 알려졌다. 서유럽의 기사들은 곧 십자군에 대한 열정을 잃어버렸다. 싸움은 스페인과 지중해, 그리고 북유럽의 이교도에 대하여 계속되고 있었다. 그러나 이 전투 이후에 발칸 반도에 대한 오스만 투르크의 전진을 막기 위해 서유럽에서 구성된 원정은 더 이상 없었다. 르네상스시대가 다가올 때까지였다.'\n",
            "'가스라이팅(gaslighting)은 상황 조작을 통해 타인의 마음에 스스로에 대한 의심을 불러일으켜 현실감과 판단력을 잃게 만듦으로써 그 사람을 정신적으로 황폐화시키고 그 사람에게 지배력을 행사하여 결국 그 사람을 파국으로 몰아가는 것을 의미하는 심리학 용어이다. 주로 친밀한 관계에서 이루어진다. 하지만 정치계나 연예계에서도 구사될 수 있다. 가스라이팅 구사자들은 상황 조작을 통해 상대방의 자아를 흔들어서 자신의 영향력을 증폭시킨다. 이를 통해 상대방을 자유자재로 가지고 놀 수 있고 그 사람이 가진 재산 등을 탈취할 수도 있다. 가스라이팅 피해자는 자신에 대한 신뢰감을 잃어가게 되고 종국에는 자존감이 없어진다. 가해자들은 상대방의 공감능력을 이용해서 상대방을 통제한다. 동정심을 이용해서 타인을 조종하는 소시오패스가 예가 될 수 있다. 이런 심리술을 이론화한 로빈 스턴은 미국에서 20여 년간 심리상담가, 교사, 우드헐리더십연구원으로 일하면서 수많은 상담을 진행해온 리더십 강사 및 컨설턴트였다.'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6jW0gXtJ-_nf"
      },
      "source": [
        "처리한 데이터를 `torch`가 처리할 수 있게 `DataLoader`로 넘겨주는 작업을 해봅시다. 기본적으로 Huggingface Pretrained 모델이 `input_ids`, `attention_mask`, `token_type_ids`를 받아주니, 이 3가지를 넣어주도록 합시다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jiacVxXFeBbK"
      },
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, TensorDataset\n",
        "\n",
        "q_seqs = tokenizer(\n",
        "    training_dataset[\"question\"],\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")\n",
        "p_seqs = tokenizer(\n",
        "    p_with_neg,\n",
        "    padding=\"max_length\",\n",
        "    truncation=True,\n",
        "    return_tensors=\"pt\"\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvzIayy79Mdy",
        "outputId": "02e08862-b73f-4bd3-c629-534c8ff88298"
      },
      "source": [
        "max_len = p_seqs[\"input_ids\"].size(-1)\n",
        "p_seqs[\"input_ids\"] = p_seqs[\"input_ids\"].view(-1, num_neg + 1, max_len)\n",
        "p_seqs[\"attention_mask\"] = p_seqs[\"attention_mask\"].view(-1, num_neg + 1, max_len)\n",
        "p_seqs[\"token_type_ids\"] = p_seqs[\"token_type_ids\"].view(-1, num_neg + 1, max_len)\n",
        "\n",
        "print(p_seqs[\"input_ids\"].size())  # (num_example, pos + neg, max_len)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([20, 3, 512])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAplp66Pkayy"
      },
      "source": [
        "train_dataset = TensorDataset(\n",
        "    p_seqs[\"input_ids\"], p_seqs[\"attention_mask\"], p_seqs[\"token_type_ids\"], \n",
        "    q_seqs[\"input_ids\"], q_seqs[\"attention_mask\"], q_seqs[\"token_type_ids\"]\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwMvVH1e3h99"
      },
      "source": [
        "### 💻 2. BERT encoder 학습시키기\n",
        "1. BERT 모델을 구성한 후\n",
        "2. Passage 를 임베딩하는 `p_encoder`와 Query/Question 을 임베딩하는 `q_encoder` 를 각각 선언해줍니다.\n",
        "3. 두 모델을 학습시킵니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T08:06:32.340866Z",
          "start_time": "2021-09-15T08:06:32.327858Z"
        },
        "id": "oKKkTlh_l5VL"
      },
      "source": [
        "class BertEncoder(BertPreTrainedModel):\n",
        "\n",
        "    def __init__(self, config):\n",
        "        super(BertEncoder, self).__init__(config)\n",
        "\n",
        "        self.bert = BertModel(config)\n",
        "        self.init_weights()\n",
        "      \n",
        "      \n",
        "    def forward(self,\n",
        "            input_ids, \n",
        "            attention_mask=None,\n",
        "            token_type_ids=None\n",
        "        ): \n",
        "  \n",
        "        outputs = self.bert(\n",
        "            input_ids,\n",
        "            attention_mask=attention_mask,\n",
        "            token_type_ids=token_type_ids\n",
        "        )\n",
        "        \n",
        "        pooled_output = outputs[1]\n",
        "        return pooled_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wnO1b30SomBP",
        "outputId": "635dec4b-33c2-4026-8fef-a6fa8f150829"
      },
      "source": [
        "# Pre-train된 모델을 사용해줍니다. 위에서 사용한 `model_checkpoint`를 재활용합니다.\n",
        "p_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
        "q_encoder = BertEncoder.from_pretrained(model_checkpoint)\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    p_encoder.cuda()\n",
        "    q_encoder.cuda()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of the model checkpoint at klue/bert-base were not used when initializing BertEncoder: ['cls.predictions.bias', 'cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.decoder.weight', 'cls.predictions.decoder.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertEncoder from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertEncoder from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f3Dgo8U997HD"
      },
      "source": [
        "`train` 함수를 정의한 후 `p_encoder`과 `q_encoder`를 학습시켜봅시다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAb7NpUc8YRo"
      },
      "source": [
        "def train(args, num_neg, dataset, p_encoder, q_encoder):\n",
        "    batch_size = args.per_device_train_batch_size\n",
        "  \n",
        "    # Dataloader\n",
        "    train_dataloader = DataLoader(dataset, batch_size=batch_size)\n",
        "\n",
        "    # Optimizer\n",
        "    no_decay = [\"bias\", \"LayerNorm.weight\"]\n",
        "    optimizer_grouped_parameters = [\n",
        "        {\"params\": [p for n, p in p_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n",
        "        {\"params\": [p for n, p in p_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0},\n",
        "        {\"params\": [p for n, p in q_encoder.named_parameters() if not any(nd in n for nd in no_decay)], \"weight_decay\": args.weight_decay},\n",
        "        {\"params\": [p for n, p in q_encoder.named_parameters() if any(nd in n for nd in no_decay)], \"weight_decay\": 0.0}\n",
        "    ]\n",
        "    optimizer = AdamW(\n",
        "        optimizer_grouped_parameters,\n",
        "        lr=args.learning_rate,\n",
        "        eps=args.adam_epsilon\n",
        "    )\n",
        "    t_total = len(train_dataloader) // args.gradient_accumulation_steps * args.num_train_epochs\n",
        "    scheduler = get_linear_schedule_with_warmup(\n",
        "        optimizer,\n",
        "        num_warmup_steps=args.warmup_steps,\n",
        "        num_training_steps=t_total\n",
        "    )\n",
        "\n",
        "    # Start training!\n",
        "    global_step = 0\n",
        "\n",
        "    p_encoder.zero_grad()\n",
        "    q_encoder.zero_grad()\n",
        "\n",
        "    p_encoder.train()\n",
        "    q_encoder.train()\n",
        "\n",
        "    torch.cuda.empty_cache()\n",
        "\n",
        "    train_iterator = trange(int(args.num_train_epochs), desc=\"Epoch\")\n",
        "    for _ in train_iterator:\n",
        "\n",
        "        # epoch_iterator = tqdm(train_dataloader, desc=\"Iteration\")\n",
        "        with tqdm(train_dataloader, unit=\"batch\") as tepoch:\n",
        "            for batch in tepoch:\n",
        "        \n",
        "                targets = torch.zeros(batch_size).long() # positive example은 전부 첫 번째에 위치하므로\n",
        "                targets = targets.to(args.device)\n",
        "\n",
        "                p_inputs = {\n",
        "                    \"input_ids\": batch[0].view(batch_size * (num_neg + 1), -1).to(args.device),\n",
        "                    \"attention_mask\": batch[1].view(batch_size * (num_neg + 1), -1).to(args.device),\n",
        "                    \"token_type_ids\": batch[2].view(batch_size * (num_neg + 1), -1).to(args.device)\n",
        "                }\n",
        "        \n",
        "                q_inputs = {\n",
        "                    \"input_ids\": batch[3].to(args.device),\n",
        "                    \"attention_mask\": batch[4].to(args.device),\n",
        "                    \"token_type_ids\": batch[5].to(args.device)\n",
        "                }\n",
        "\n",
        "                del batch\n",
        "                torch.cuda.empty_cache()\n",
        "                # (batch_size * (num_neg + 1), emb_dim)\n",
        "                p_outputs = p_encoder(**p_inputs)\n",
        "                # (batch_size, emb_dim)  \n",
        "                q_outputs = q_encoder(**q_inputs)\n",
        "\n",
        "                # Calculate similarity score & loss\n",
        "                p_outputs = p_outputs.view(batch_size, -1, num_neg + 1)\n",
        "                q_outputs = q_outputs.view(batch_size, 1, -1)\n",
        "\n",
        "                # (batch_size, num_neg + 1)\n",
        "                sim_scores = torch.bmm(q_outputs, p_outputs).squeeze()  \n",
        "                sim_scores = sim_scores.view(batch_size, -1)\n",
        "                sim_scores = F.log_softmax(sim_scores, dim=1)\n",
        "\n",
        "                loss = F.nll_loss(sim_scores, targets)\n",
        "                tepoch.set_postfix(loss=f\"{str(loss.item())}\")\n",
        "\n",
        "                loss.backward()\n",
        "                optimizer.step()\n",
        "                scheduler.step()\n",
        "\n",
        "                q_encoder.zero_grad()\n",
        "                p_encoder.zero_grad()\n",
        "\n",
        "                global_step += 1\n",
        "\n",
        "                torch.cuda.empty_cache()\n",
        "                del p_inputs, q_inputs\n",
        "\n",
        "    return p_encoder, q_encoder"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ICSJoJrUDGZ5"
      },
      "source": [
        "args = TrainingArguments(\n",
        "    output_dir=\"dense_retireval\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=2, # 아슬아슬합니다. 작게 쓰세요 !\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01,\n",
        ")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I5h7_-aRA9dm"
      },
      "source": [
        "_혹시 CUDA 메모리 에러가 뜬다면 passage encoder 와 query encoder 를 나누지 말고 하나로 학습해보세요. `batch_size`도 변경해보세요._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8a7ww3WgsaZ",
        "outputId": "fbbd90b3-b569-450c-8054-692333666768"
      },
      "source": [
        "p_encoder, q_encoder = train(args, num_neg, train_dataset, p_encoder, q_encoder)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 10/10 [02:12<00:00, 13.29s/batch, loss=0.0]\n",
            "100%|██████████| 10/10 [02:28<00:00, 14.84s/batch, loss=0.0]\n",
            "Epoch: 100%|██████████| 2/2 [04:41<00:00, 140.66s/it]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BGOw-k7Ln85t"
      },
      "source": [
        "### 💻 3. 검증셋에 있는 Query 에 대해 passage-retrieval 해보기\n",
        "이제 처음 보는 검증셋에 있는 Query 와 passage 에 대해서도 잘 작동하는지 확인해봅시다. 아래와 같은 순서로 작동해야겠죠?\n",
        "1. 검증셋을 불러온다.\n",
        "2. 검증셋의 query 와 passage 를 임베딩시킨다.\n",
        "3. 유사도를 통해 유사한 주어진 query 에 맞는 passage 를 찾는다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FZA5V6tEpuUV"
      },
      "source": [
        "#### 💻 검증셋 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NouB9uBcTaws",
        "outputId": "d20d885c-d7cf-481f-f5fa-66b3952236b5"
      },
      "source": [
        "valid_corpus = list(set([example[\"context\"] for example in dataset[\"validation\"]]))[:10]\n",
        "\n",
        "sample_idx = random.choice(range(len(dataset[\"validation\"])))\n",
        "query = dataset[\"validation\"][sample_idx][\"question\"]\n",
        "ground_truth = dataset[\"validation\"][sample_idx][\"context\"]\n",
        "\n",
        "if not ground_truth in valid_corpus:\n",
        "    valid_corpus.append(ground_truth)\n",
        "\n",
        "print(f\"[Selected Query]\")\n",
        "pprint(query)\n",
        "\n",
        "print(f\"[Ground Truth]\")\n",
        "pprint(ground_truth)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "----- [Selected Query] -----\n",
            "'SBS 연기대상에서 김태희는 무슨 상을 받았나?'\n",
            "\n",
            "----- [Ground Truth] -----\n",
            "('2001년 영화 《선물》에 이영애의 아역으로 출연하면서 연기자로 입문하였고, 2002년 독립 영화 《신도시인》에 출연했다. 이후 '\n",
            " '시트콤《레츠고》(2002), 《스크린》, 《흥부네 박터졌네》(2003)와 같은 텔레비전 드라마에 출연했다. 2003년에는 《천국의 '\n",
            " '계단》에서 악역 한유리 역할로 얼굴을 알리며 인기를 얻기 시작했고, 이 드라마로 SBS 연기대상에서 뉴스타상을 수상했다. 2004년에는 '\n",
            " '드라마 《구미호 외전》과 《러브스토리 인 하버드》에 출연했다. 하지만 이후 영화 《중천》(2006), 《싸움》(2007)에 출연했으나, '\n",
            " '모두 흥행에 실패했다. 2009년에는 시청률 30%대를 기록한 드라마 《아이리스》에서 최승희 역할을 연기해 KBS 연기대상에서 '\n",
            " '우수연기상을 수상하였다. 이후 드라마 《마이프린세스》(2011), 《나와 스타의 99일》(2012), 《장옥정 사랑에 '\n",
            " '살다》(2013)에서 주연으로 출연했고, 2015년 드라마 《용팔이》로 SBS 연기대상 최우수연기상을 수상했다.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "05D8GzFrJhHO"
      },
      "source": [
        "#### 💻 앞서 학습한 passage encoder, question encoder 을 이용해 dense embedding 생성하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YufA_ayPJBRg",
        "outputId": "cd5720b6-46c9-4da6-d5dc-d480868348e4"
      },
      "source": [
        "with torch.no_grad():\n",
        "    p_encoder.eval()\n",
        "    q_encoder.eval()\n",
        "\n",
        "    q_seqs_val = tokenizer(\n",
        "        [query],\n",
        "        padding=\"max_length\",\n",
        "        truncation=True,\n",
        "        return_tensors=\"pt\"\n",
        "    ).to(\"cuda\")\n",
        "    q_emb = q_encoder(**q_seqs_val).to(\"cpu\")  # (num_query, emb_dim)\n",
        "\n",
        "    p_embs = []\n",
        "    for p in valid_corpus:\n",
        "        p = tokenizer(\n",
        "            p,\n",
        "            padding=\"max_length\",\n",
        "            truncation=True,\n",
        "            return_tensors=\"pt\"\n",
        "        ).to(\"cuda\")\n",
        "        p_emb = p_encoder(**p).to(\"cpu\").numpy()\n",
        "        p_embs.append(p_emb)\n",
        "\n",
        "p_embs = torch.Tensor(p_embs).squeeze()  # (num_passage, emb_dim)\n",
        "print(p_embs.size(), q_emb.size())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([11, 768]) torch.Size([1, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pOHHak7WS1ko"
      },
      "source": [
        "#### 💻 Dot product를 통해 유사도 구하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xn5Cx5JkKZJB",
        "outputId": "84d37434-bfe5-4a6f-d160-d0ca72d65bcd"
      },
      "source": [
        "dot_prod_scores = torch.matmul(q_emb, torch.transpose(p_embs, 0, 1))\n",
        "print(dot_prod_scores.size())\n",
        "\n",
        "rank = torch.argsort(dot_prod_scores, dim=1, descending=True).squeeze()\n",
        "print(dot_prod_scores)\n",
        "print(rank)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 11])\n",
            "tensor([[176.3418, 147.5652, 165.1897, 177.7192, 148.4269, 156.9671, 166.3144,\n",
            "         155.8632, 150.4935, 141.3773, 166.0702]])\n",
            "tensor([ 3,  0,  6, 10,  2,  5,  7,  8,  4,  1,  9])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Oq2Oiv8MKVS6"
      },
      "source": [
        "#### 💻 Top-5개의 passage를 retrieve 하고 ground truth와 비교하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WaStRXYdJ-wI",
        "outputId": "9d93531f-8e65-43c7-dfdc-a1184963362f"
      },
      "source": [
        "k = 5\n",
        "print(\"[Search query]\\n\", query, \"\\n\")\n",
        "print(\"[Ground truth passage]\")\n",
        "print(ground_truth, \"\\n\")\n",
        "\n",
        "for i in range(k):\n",
        "  print(f\"Top-{i + 1} passage with score {dot_prod_scores.squeeze()[rank[i]]}:.4f\")\n",
        "  pprint(valid_corpus[rank[i]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Search query]\n",
            " SBS 연기대상에서 김태희는 무슨 상을 받았나? \n",
            "\n",
            "[Ground truth passage]\n",
            "2001년 영화 《선물》에 이영애의 아역으로 출연하면서 연기자로 입문하였고, 2002년 독립 영화 《신도시인》에 출연했다. 이후 시트콤《레츠고》(2002), 《스크린》, 《흥부네 박터졌네》(2003)와 같은 텔레비전 드라마에 출연했다. 2003년에는 《천국의 계단》에서 악역 한유리 역할로 얼굴을 알리며 인기를 얻기 시작했고, 이 드라마로 SBS 연기대상에서 뉴스타상을 수상했다. 2004년에는 드라마 《구미호 외전》과 《러브스토리 인 하버드》에 출연했다. 하지만 이후 영화 《중천》(2006), 《싸움》(2007)에 출연했으나, 모두 흥행에 실패했다. 2009년에는 시청률 30%대를 기록한 드라마 《아이리스》에서 최승희 역할을 연기해 KBS 연기대상에서 우수연기상을 수상하였다. 이후 드라마 《마이프린세스》(2011), 《나와 스타의 99일》(2012), 《장옥정 사랑에 살다》(2013)에서 주연으로 출연했고, 2015년 드라마 《용팔이》로 SBS 연기대상 최우수연기상을 수상했다. \n",
            "\n",
            "Top-1 passage with score 177.71917724609375:.4f\n",
            "('2013년 12월부터는 SBS 드라마 《별에서 온 그대》에 한류 스타 천송이 역으로 출연했다. 이는 1999년 《해피투게더》 이후 14년 '\n",
            " '만의 드라마 작품으로, 이 전에 《도둑들》에서 함께 했던 김수현과 주연을 맡았다. 《별에서 온 그대》는 최고 시청률 28.1%, 평균 '\n",
            " '시청률 22.6%를 기록하며 단 한 번도 동시간대 시청률 1위를 놓친 적이 없다. 이 드라마로 2014년 5월 27일 열린 제50회 '\n",
            " '백상예술대상에서 TV 대상을 포함해 InStyle상까지 2관왕에 올랐다. 같은 해 《별에서 온 그대》로 2014년 SBS 연기대상에서 '\n",
            " '최고상인 대상과 베스트 커플상, 10대 스타상, 프로듀서상을 수상하여 4관왕에 올랐다.')\n",
            "Top-2 passage with score 176.34176635742188:.4f\n",
            "('1976년 10월 공군에 입대해 사병으로 복무 중인, 1978년 12월에 독일 분데스리가 SV 다름슈타트 98로 이적하였지만 병역 관련 '\n",
            " '문제로 계약이 파기되었다. (당시 차범근은 공군 팀 전력 강화를 꾀하던 참모총장의 권한으로 2년 뒤 전역을 약속받고, 공군에 입대하였다. '\n",
            " '약속된 1978년 12월 복무 기간을 마쳤다고 생각하고, 특별 휴가를 받아 독일로 떠나 SV 다름슈타트 98 입단 계약을 체결하였고 '\n",
            " '12월 30일 VfL 보훔과의 리그 경기에 출전해서 77분을 소화했고, 키커 평점 3점을 받는 등 좋은 활약을 펼치며 분데스리가 데뷔전을 '\n",
            " '성공적으로 끝마쳤다. 그러나 공군의 입장 변화로 1979년 1월 5일 다시 귀국한 후, 복귀해서 독일로 다시 나가지 못하고 1979년 '\n",
            " '5월 31일 만기 전역하였다.')\n",
            "Top-3 passage with score 166.31443786621094:.4f\n",
            "('국토교통부는 2015년까지 100년 주택인 장수명 아파트 인증제 도입을 추진한다고 보도했다. 유럽이나 미국의 경우, 100년된 주택을 '\n",
            " '쉽게 찿을수 있지만 고도의 성장에 있어 40년 넘은 주택조차 찿기 어려운것에 대한 조치이다. 서울시는 최근 근현대 문물 보존 프로잭트인 '\n",
            " '미래문화유산화의 일부보존 대상으로 아파트 10군데를 후보로 지정하였다. 가장오래된 충정아파트(1933), 동대문아파트 (1965)을 '\n",
            " '비롯해 정동아파트 (1965), 힐탑아파트 (1967), 회현제2시민아파트 (1970), 여의도시범아파트 (1971), 성요셉아파트 '\n",
            " '(1971), 서소문아파트 (1972), 반포본동아파트 (1973), 개포주공1단지아파트 (1981)가 선정되었으며 소유자의 동의를 받고 '\n",
            " '지정될 예정이다.')\n",
            "Top-4 passage with score 166.0701904296875:.4f\n",
            "('2001년 영화 《선물》에 이영애의 아역으로 출연하면서 연기자로 입문하였고, 2002년 독립 영화 《신도시인》에 출연했다. 이후 '\n",
            " '시트콤《레츠고》(2002), 《스크린》, 《흥부네 박터졌네》(2003)와 같은 텔레비전 드라마에 출연했다. 2003년에는 《천국의 '\n",
            " '계단》에서 악역 한유리 역할로 얼굴을 알리며 인기를 얻기 시작했고, 이 드라마로 SBS 연기대상에서 뉴스타상을 수상했다. 2004년에는 '\n",
            " '드라마 《구미호 외전》과 《러브스토리 인 하버드》에 출연했다. 하지만 이후 영화 《중천》(2006), 《싸움》(2007)에 출연했으나, '\n",
            " '모두 흥행에 실패했다. 2009년에는 시청률 30%대를 기록한 드라마 《아이리스》에서 최승희 역할을 연기해 KBS 연기대상에서 '\n",
            " '우수연기상을 수상하였다. 이후 드라마 《마이프린세스》(2011), 《나와 스타의 99일》(2012), 《장옥정 사랑에 '\n",
            " '살다》(2013)에서 주연으로 출연했고, 2015년 드라마 《용팔이》로 SBS 연기대상 최우수연기상을 수상했다.')\n",
            "Top-5 passage with score 165.18966674804688:.4f\n",
            "('1953년 3월 24일 전라북도 고창군에서 태어난 김이수는 고수국민학교, 광주서중학교, 전남고등학교와 서울대학교 법학과를 졸업했다. '\n",
            " '대학교 3학년인 1974년 민청학련 사건에 연루돼 64일간 구금됐다가 석방되었다. 1977년 제19회 사법시험에 합격해 사법연수원 9기를 '\n",
            " '수료하고 1979년 12월 31일에 사단 군검찰관으로 임관해 5개월 후인 1980년 5월 법무사 군 판사로서 5·18 항쟁 시민군을 태운 '\n",
            " '버스 운전사에게 사형을 선고했다. 이를 지적하는 새누리당 함진규 의원의 지적에 \"안 맡았으면 좋았을 재판이라고 지금도 생각한다\"며 \"광주 '\n",
            " '사람으로서 광주항쟁에 참여해야할 입장이었는데 재판을 맡게 됐다. 아주 복잡한 입장이었다\"고 말했으며 \"시민군 가담 여고생에게 징역 1년을 '\n",
            " '선고하고 50살 농민을 구금하고 징역 2년 집행유예 3년 선고했다. 군의 살상행위를 알린 현직 이장에게 유언비어 유포죄로 징역 1년 집유 '\n",
            " '2년을 선고했다\"는 새누리당 의원의 지적에는 \"기록을 검토해봐야 한다. 판결문만 보면 모순이 있는 것 같다\"고 했다. 5·16 '\n",
            " '군사쿠데타에 관해서 \"권력을 잡는 방법은 비정상적이었지만 권력을 잡은 측면과 전체를 한꺼번에 봐야한다\"며 \"10월 유신까지 가는 부분에는 '\n",
            " '공과가 있다\"고 했다.')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cicYTii7jZZC"
      },
      "source": [
        "Ground Truth와 똑같거나 비슷한 Passage가 출력됐나요? 역시 Pretrained는 강력하군요.\n",
        "### ❓ Dense Retrieval 코드를 class로 합쳐봅시다.\n",
        "현재 구현된 모델은 굉장히 단순히 짜여졌습니다. 이미 Pretrain된 BERT 모델을 활용했는데, 다른 PLM은 어떨까요? 이를 다시 시도해보자니 코드가 너무 셀로 흩어져있어서 재사용이 어렵네요. 우선 클래스화를 진햏한 후에, `BERT`가 아닌 다른 PLM도 활용해봅시다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "on_Ay5_nbqEc"
      },
      "source": [
        "❗ _Hint_   \n",
        "Scratch부터 짜는게 많이 어려우신가요?\n",
        "\n",
        "만들어야하는 기능들의 파이프라인을 나열하고 하나씩 모듈화하는 습관을 들이는 것이 좋습니다. 순서대로 생각해볼까요?\n",
        "\n",
        "1. Setup   \n",
        "    Naive한 `Dataset`을 받아서 이를 In-Batch Negative를 활용한 후 Dataloader로 변경해주는 코드가 있어야겠죠? 클래스 내에서 활용할 수 있도록 속성(attribute)으로 만들어줍시다. 이 코드를 위에서 활용한 `train` 함수에서 조금 차용해볼까요?\n",
        "2. PLM을 주어진 Passage 와 In-batch negative 기법을 활용해서 훈련합니다.   \n",
        "    이는 위에서 만든 `train` 함수를 약간 응용해서 재활용합시다.\n",
        "3. 훈련한 PLM 을 통해 Query 를 Transform 합니다.\n",
        "4. 내적을 통해 유사도를 구하고, 내림차순을 통해 유사한 Passage 를 Retrieval 합니다.\n",
        "\n",
        "위 4단계를 하나씩 함수로 구현한 후 Class로 합치면 훨씬 쉬울 겁니다!"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T08:06:47.410939Z",
          "start_time": "2021-09-15T08:06:46.140856Z"
        },
        "id": "994wDYAujsLr"
      },
      "source": [
        "# 코드가 많아보이지만 주석이 더 많지롱\n",
        "class DenseRetrieval:\n",
        "    def __init__(self,\n",
        "        args,\n",
        "        dataset,\n",
        "        num_neg,\n",
        "        tokenizer,\n",
        "        p_encoder,\n",
        "        q_encoder\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            args (Huggingface Arguments):\n",
        "                세팅과 학습에 필요한 설정값을 받습니다.\n",
        "            dataset (datasets.Dataset):\n",
        "                Huggingface의 Dataset을 받아옵니다.\n",
        "            num_neg (int):\n",
        "                In-batch negative 수행시 사용할 negative sample의 수를 받아옵니다.\n",
        "            tokenizer (Callable):\n",
        "                Tokenize할 함수를 받아옵니다.\n",
        "                아래와 같은 함수들을 사용할 수 있습니다.\n",
        "                - lambda x: x.split(' ')\n",
        "                - Huggingface Tokenizer\n",
        "                - konlpy.tag의 Mecab\n",
        "            p_encoder (torch.nn.Module):\n",
        "                Passage를 Dense Representation으로 임베딩시킬 모델입니다.\n",
        "            q_encoder (torhc.nn.Module):\n",
        "                Query를 Dense Representation으로 임베딩시킬 모델입니다.\n",
        "\n",
        "        Summary:\n",
        "            학습과 추론에 필요한 객체들을 받아서 속성으로 저장합니다.\n",
        "            객체가 instantiate될 때 in-batch negative가 생긴 데이터를 만들도록 함수를 수행합니다.\n",
        "        \"\"\"\n",
        "\n",
        "        self.args = args\n",
        "        self.dataset = dataset\n",
        "        self.num_neg = num_neg\n",
        "\n",
        "        self.tokenizer = tokenizer\n",
        "        self.p_encoder = p_encoder.to(args.device)\n",
        "        self.q_encoder = q_encoder.to(args.device)\n",
        "\n",
        "        self.prepare_in_batch_negative(num_neg=num_neg)\n",
        "\n",
        "\n",
        "    def prepare_in_batch_negative(self,\n",
        "        dataset=None,\n",
        "        num_neg=2,\n",
        "        tokenizer=None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            dataset (datasets.Dataset, default=None):\n",
        "                Huggingface의 Dataset을 받아오면,\n",
        "                in-batch negative를 추가해서 Dataloader를 만들어주세요.\n",
        "            num_neg (int, default=2):\n",
        "                In-batch negative 수행시 사용할 negative sample의 수를 받아옵니다.\n",
        "            tokenizer (Callable, default=None):\n",
        "                Tokenize할 함수를 받아옵니다.\n",
        "                별도로 받아오지 않으면 속성으로 저장된 Tokenizer를 불러올 수 있게 짜주세요.\n",
        "\n",
        "        Note:\n",
        "            모든 Arguments는 사실 이 클래스의 속성으로 보관되어 있기 때문에\n",
        "            별도로 Argument를 직접 받지 않아도 수행할 수 있게 만들어주세요.\n",
        "        \"\"\"\n",
        "        if dataset is None:\n",
        "            dataset = self.dataset\n",
        "\n",
        "\n",
        "    def train(self,\n",
        "        args=None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Summary:\n",
        "            train을 합니다. 위에 과제에서 이용한 코드를 활용합시다.\n",
        "            encoder들과 dataloader가 속성으로 저장되어있는 점에 유의해주세요.\n",
        "        \"\"\"\n",
        "        pass\n",
        "\n",
        "\n",
        "    def get_relevant_doc(self,\n",
        "        query,\n",
        "        k=1,\n",
        "        args=None\n",
        "    ):\n",
        "        \"\"\"\n",
        "        Arguments:\n",
        "            query (str)\n",
        "                문자열로 주어진 질문입니다.\n",
        "            k (int, default=1)\n",
        "                상위 몇 개의 유사한 passage를 뽑을 것인지 결정합니다.\n",
        "            args (Huggingface Arguments, default=None)\n",
        "                Configuration을 필요한 경우 넣어줍니다.\n",
        "                만약 None이 들어오면 self.args를 쓰도록 짜면 좋을 것 같습니다.\n",
        "\n",
        "        Summary:\n",
        "            1. query를 받아서 embedding을 하고\n",
        "            2. 전체 passage와의 유사도를 구한 후\n",
        "            3. 상위 k개의 문서 index를 반환합니다.\n",
        "        \"\"\"\n",
        "        pass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T08:06:50.333519Z",
          "start_time": "2021-09-15T08:06:47.419925Z"
        },
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 67,
          "referenced_widgets": [
            "1b16d8e4c2d74aab9fdda9ae60c21441",
            "58ca9dbe05d149fcb73677736541c1ce",
            "92cbaf4e42694aca93e327941b1c9422",
            "e4c5ce6351014015aa41d8a43fdca7d8",
            "9407250e75c14524be3fa222b02c4f74",
            "e38d794604bb409bb4d41a5bfef5eb61",
            "0a78e445530c4d93a2ccce5bcda351da",
            "3fe1fbff472c435c94c25c1736081373",
            "430873d31e5c4770afd48183c1a8f1de",
            "3ad885d798e64e35ae6705412494a52e",
            "be78ee5fbd55487fb3dd0da23adbc154"
          ]
        },
        "id": "cBr57rLvkM68",
        "outputId": "1bcc0a3e-90b7-44cb-c772-91a88df16f93"
      },
      "source": [
        "# 데이터셋과 모델은 아래와 같이 불러옵니다.\n",
        "train_dataset = load_dataset(\"squad_kor_v1\")[\"train\"]\n",
        "\n",
        "# 메모리가 부족한 경우 일부만 사용하세요 !\n",
        "num_sample = 1500\n",
        "sample_idx = np.random.choice(range(len(train_dataset)), num_sample)\n",
        "train_dataset = train_dataset[sample_idx]\n",
        "\n",
        "args = TrainingArguments(\n",
        "    output_dir=\"dense_retireval\",\n",
        "    evaluation_strategy=\"epoch\",\n",
        "    learning_rate=2e-5,\n",
        "    per_device_train_batch_size=2,\n",
        "    per_device_eval_batch_size=2,\n",
        "    num_train_epochs=2,\n",
        "    weight_decay=0.01\n",
        ")\n",
        "model_checkpoint = \"klue/bert-base\"\n",
        "\n",
        "# 혹시 위에서 사용한 encoder가 있다면 주석처리 후 진행해주세요 (CUDA ...)\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)\n",
        "p_encoder = BertEncoder.from_pretrained(model_checkpoint).to(args.device)\n",
        "q_encoder = BertEncoder.from_pretrained(model_checkpoint).to(args.device)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Reusing dataset squad_kor_v1 (/root/.cache/huggingface/datasets/squad_kor_v1/squad_kor_v1/1.0.0/18d4f44736b8ee85671f63cb84965bfb583fa0a4ff2df3c2e10eee9693796725)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1b16d8e4c2d74aab9fdda9ae60c21441",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/2 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "ExecuteTime": {
          "end_time": "2021-09-15T08:06:50.335488Z",
          "start_time": "2021-09-15T08:06:50.335488Z"
        },
        "id": "8aUOE8VEyZ1v",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1b78b56c-a84c-4e5f-8d4a-43afe8dd0c2d"
      },
      "source": [
        "# Retriever는 아래와 같이 사용할 수 있도록 코드를 짜봅시다.\n",
        "retriever = DenseRetrieval(\n",
        "    args=args,\n",
        "    dataset=train_dataset,\n",
        "    num_neg=2,\n",
        "    tokenizer=tokenizer,\n",
        "    p_encoder=p_encoder,\n",
        "    q_encoder=q_encoder\n",
        ")\n",
        "\n",
        "retriever.train()\n",
        "\n",
        "query = \"유아인에게 타고난 배우라고 말한 드라마 밀회의 감독은?\"\n",
        "results = retriever.get_relevant_doc(query=query, k=5)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Iteration: 100%|██████████| 750/750 [01:34<00:00,  7.91it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YKKMfYhREui4",
        "outputId": "ef512c8c-f8d6-4b6f-d124-24c438529faf"
      },
      "source": [
        "print(f\"[Search Query] {query}\")\n",
        "\n",
        "indices = result[1]\n",
        "for i, idx in enumerate(indices):\n",
        "    print(f\"Top-{i + 1}th Passage (Index {idx})\")\n",
        "    pprint(retriever.contexts[idx])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[Search query]\n",
            " 유아인에게 타고난 배우라고 말한 드라마 밀회의 감독은? \n",
            "\n",
            "[Predicted Passage]\n",
            "('한편 2009년 헐리우드 메이저 영화 단독 주연으로 \"닌자 어쌔신\" 개봉하였고 2010년 6월 6일 아시아 한국인 최초로 미국 LA에서 '\n",
            " '열린 제 19회 \"2010 엠티비 무비 어워드(MTV Movie Awards)에서 최고의 액션스타상(Biggest Badass '\n",
            " 'Star)을 수상하였다. 아시아 최초 첫 단독 주연 액션스타상은 비가 최초이다. 또한 미국의 배우 안젤리나 졸리는 한 언론과의 인터뷰에서 '\n",
            " '비는 정말 대단하다며 극찬을 펼치기도 했었다. 2011년 아시아 연예인 최초로 미국 타임 세계에서 가장 영향력 있는 100인에 2회 '\n",
            " '선정되었다. 미국 타임 100인 선정은 타임 심사 위원들의 심사를 거쳐 선정하는데 가능하면 과거에 뽑힌 인물은 중복해서 선정하지 않는 게 '\n",
            " '원칙이고 인터넷 투표는 참고사항일뿐이라고 타임지는 밝혔습니다. 비는 지금까지 온라인 인기투표 리스트에 총 6회 이름이 올려줬다.[1]')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TwE-zCr2CIiq"
      },
      "source": [
        "#### ➕추가 과제: 다양한 기능 추가하기\n",
        "현재 코드에서 불편한 부분이 있죠. 일단 너무 많은 기능을 한 class에 넣은 것도 문제, 메소드도 한 번에 너무 다양한 기능을 하는 것이 문제입니다. 메소드 내의 기능을 쪼개서 여러 메소드로 나누거나 데이터셋을 만드는 부분 같이 큰 기능을 다른 class로 분리해봅시다. (DPR 추가 과제는 예시 코드가 제공되지 않습니다. 다양하게 활용해보세요 !)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sU8A2bpXnIOL"
      },
      "source": [
        "### ❓ Sparse Retrieval과 Dense Retrieval을 둘 다 시도해보았습니다. 어떤 차이가 있을까요? 팀원들과 논의해보세요."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8KO4AmLhr_G"
      },
      "source": [
        "## ❓ 과제: Wikipedia documents에 대해 Passage Retrieval 실습하기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fnvVrapPmcCO"
      },
      "source": [
        "위에서 배운 Passage Retrieval을 Wikipedia에 있는 문서들로 진행해봅시다. 사실 위에서 두 클래스를 성공적으로 만들었다면, 데이터를 불러온 후 적용만 시키면 끝이 납니다.   \n",
        "***별도의 예시코드가 제공되지 않습니다**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BC2AVU0m6OoV"
      },
      "source": [
        "# 츄라이 츄라이"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74EO3anZnbga"
      },
      "source": [
        "만족스러운 결과가 나왔나요? 그렇지 않았다면 모델의 구조를 바꾸거나, 더 많은 training set으로 학습 시켜보세요 !"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "A3j0VhH-kU9e"
      },
      "source": [
        "### ❓ Take-home Question\n",
        "이 QA 모델을 배포한다고 생각해봅시다. 성능이 좋아서 점점 이용자가 많아지는 상황입니다. 만약 동시에 1000명의 이용자가 Query 를 보내면 어떻게 될까요? 전체 Passage가 100,000 개라면, 이 유사도를 계산하고 비교하는 횟수는 ... 점점 많아질 것 같네요. 이 문제는 어떻게 해결하면 좋을까요?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dCWS-F5haN6_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}