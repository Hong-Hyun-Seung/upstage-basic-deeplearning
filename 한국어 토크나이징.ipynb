{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "(2강) 자연어의 전처리 - 1_한국어_토크나이징.ipynb의 사본",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CefqwfbCGMiY"
      },
      "source": [
        "# 한국어 Tokenizing\n",
        "\n",
        "> 작성자      \n",
        "```\n",
        "* 김성현 (bananaband657@gmail.com)  \n",
        "1기 멘토\n",
        "김바다 (qkek983@gmail.com)\n",
        "박상희 (parksanghee0103@gmail.com)  \n",
        "이정우 (jungwoo.l2.rs@gmail.com)\n",
        "2기 멘토\n",
        "박상희 (parksanghee0103@gmail.com)  \n",
        "이정우 (jungwoo.l2.rs@gmail.com)\n",
        "이녕우 (leenw2@gmail.com)\n",
        "박채훈 (qkrcogns2222@gmail.com)\n",
        "```\n",
        "[CC BY-NC-ND](https://creativecommons.org/licenses/by-nc-nd/2.0/kr/)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3w3Aj8wyGSDC"
      },
      "source": [
        "\n",
        "한국어에서의 다양한 tokenizing 방식을 실습해보겠습니다.   \n",
        "\n",
        "한국어는 다음의 단계로 tokenizing이 가능합니다.\n",
        "\n",
        "1. 어절 단위\n",
        "2. 형태소 단위\n",
        "3. 음절 단위\n",
        "4. 자소 단위\n",
        "5. WordPiece 단위"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GQo6eH7lHSIs"
      },
      "source": [
        "## 0. 실습용 데이터 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "74i60OsjHWxv"
      },
      "source": [
        "실습을 위해 한국어 wikipedia 파일을 가져오도록 하겠습니다.   \n",
        "본 wikipedia 파일은 앞선 전처리 실습을 통해 전처리가 완료된 파일입니다.   \n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7hVOadsRHjAg"
      },
      "source": [
        "!mkdir my_data"
      ],
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_3TCM_PGHKzT",
        "outputId": "60d06395-078d-480a-c18e-db2b171f0457"
      },
      "source": [
        "!curl -c ./cookie -s -L \"https://drive.google.com/uc?export=download&id=1zib1GI8Q5wV08TgYBa2GagqNh4jyfXZz\" > /dev/null\n",
        "!curl -Lb ./cookie \"https://drive.google.com/uc?export=download&confirm=`awk '/download/ {print $NF}' ./cookie`&id=1zib1GI8Q5wV08TgYBa2GagqNh4jyfXZz\" -o my_data/wiki_20190620_small.txt"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "100   408    0   408    0     0   1040      0 --:--:-- --:--:-- --:--:--  1038\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "  0     0    0     0    0     0      0      0 --:--:--  0:00:01 --:--:--     0\n",
            "100 1323k  100 1323k    0     0   714k      0  0:00:01  0:00:01 --:--:--  714k\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03NyUBPvH0kv"
      },
      "source": [
        "데이터를 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AxajxY2LH2zv"
      },
      "source": [
        "data = open('my_data/wiki_20190620_small.txt', 'r', encoding='utf-8')\n",
        "# 'r' 은 read를 의미합니다.\n",
        "# 본 파일은 encoding format을 UTF-8로 저장했기 때문에, UTF-8로 읽겠습니다.\n",
        "# 한국어는 특히 encoding format이 맞지 않으면, 글자가 깨지는 현상이 나타납니다."
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ma6W4JS4IcuV"
      },
      "source": [
        "lines = data.readlines() # 전체 문장을 list(lines)에 저장하는 함수입니다."
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "L9wGJhBcIiTk",
        "outputId": "06112dab-d562-4947-ef39-99fe8aeff819"
      },
      "source": [
        "for line in lines[0:10]:\n",
        "    print(line)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "제임스 얼 \"지미\" 카터 주니어는 민주당 출신 미국 39번째 대통령 이다.\n",
            "\n",
            "지미 카터는 조지아주 섬터 카운티 플레인스 마을에서 태어났다.\n",
            "\n",
            "조지아 공과대학교를 졸업하였다.\n",
            "\n",
            "그 후 해군에 들어가 전함·원자력·잠수함의 승무원으로 일하였다.\n",
            "\n",
            "1953년 미국 해군 대위로 예편하였고 이후 땅콩·면화 등을 가꿔 많은 돈을 벌었다.\n",
            "\n",
            "그의 별명이 \"땅콩 농부\" 로 알려졌다.\n",
            "\n",
            "1962년 조지아 주 상원 의원 선거에서 낙선하나 그 선거가 부정선거 였음을 입증하게 되어 당선되고, 1966년 조지아 주 지사 선거에 낙선하지만 1970년 조지아 주 지사를 역임했다.\n",
            "\n",
            "대통령이 되기 전 조지아주 상원의원을 두번 연임했으며, 1971년부터 1975년까지 조지아 지사로 근무했다.\n",
            "\n",
            "조지아 주지사로 지내면서, 미국에 사는 흑인 등용법을 내세웠다.\n",
            "\n",
            "1976년 대통령 선거에 민주당 후보로 출마하여 도덕주의 정책으로 내세워, 포드를 누르고 당선되었다.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RO-HFWPVJT69"
      },
      "source": [
        "## 1. 어절 단위 tokenizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2-BGhE1OGIj"
      },
      "source": [
        "어절 단위 tokenizing은 모든 문장을 띄어쓰기 단위로 분리하는 것을 의미합니다.\n",
        "\n",
        "\"이순신은 조선 중기의 무신이다.\" -> [\"이순신은\", \"조선\", \"중기의\", \"무신이다.\"]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "te9R8Jg0P-Gp",
        "outputId": "14dffe00-a0a7-4fa6-fde3-3692d84e627b"
      },
      "source": [
        "text = \"이순신은 조선 중기의 무신이다.\"\n",
        "tokenized_text = text.split(\" \")    # split 함수는 입력 string에 대해서 특정 string을 기반으로 분리해줍니다.\n",
        "print(tokenized_text)  "
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이순신은', '조선', '중기의', '무신이다.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1DRj6iviWeJp"
      },
      "source": [
        "Tokenizing의 목적은 크게 두 가지입니다.  \n",
        "1. 의미를 지닌 단위로 자연어를 분절\n",
        "2. Model의 학습 시(문장을 어절 단위로 분리 한 뒤 어절 마다 0,2,1과 같이 labeling을 해준다), 동일한 size로 입력(model마다 input의 batch size가 있다. 이때 size가 동일해야 한다->ex)만약 batch size가 10인데 input 단어 개수가 8개면 padding으로 2개를 채우고, 15개가 input이면 잘라야 한다)\n",
        "\n",
        "따라서, tokenizer는 특정 사이즈로 token의 개수를 조절하는 함수가 필수로 포함되어야 합니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9LGjc5YkXbln"
      },
      "source": [
        "이를 위해, token의 개수가 부족할 때는 padding 처리를 해주고,    \n",
        "개수가 많을 때는 token을 잘라서 반환하는 함수를 구현하겠습니다.   "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1OGGjfSOXRlQ",
        "outputId": "a199d835-50d6-49f3-9ded-b82ccb712390"
      },
      "source": [
        "#input이 padding보다 더 짧은 경우\n",
        "max_seq_length = 10\n",
        "# padding\n",
        "tokenized_text += [\"padding\"] * (max_seq_length - len(tokenized_text))\n",
        "print(tokenized_text)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이순신은', '조선', '중기의', '무신이다.', 'padding', 'padding', 'padding', 'padding', 'padding', 'padding']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t66zK6CeYD98",
        "outputId": "9ed1406e-e7d4-42b3-f82b-ddeaebc9624c"
      },
      "source": [
        "#input이 padding보다 더 긴 경우-> 잘라줘야 한다\n",
        "max_seq_length = 2\n",
        "# filtering\n",
        "tokenized_text = tokenized_text[0:max_seq_length]\n",
        "print(tokenized_text)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이순신은', '조선']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uqzv-evGZFax"
      },
      "source": [
        "위 코드를 이용해 tokenizer class를 만들어보겠습니다.\n",
        "(걍 위에 코드들을 더 이쁘게 class화 시킨것)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ALyO6-0AOFhx"
      },
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self):\n",
        "        self.tokenizer_type_list = [\"word\"]\n",
        "        self.pad_token = \"<pad>\"\n",
        "        self.max_seq_length = 10\n",
        "        self.padding = False\n",
        "    def tokenize(self, text, tokenizer_type): \n",
        "        assert tokenizer_type in self.tokenizer_type_list, \"정의되지 않은 tokenizer_type입니다.\"\n",
        "        if tokenizer_type == \"word\": #tokenizer의 type이 word면\n",
        "            tokenized_text = text.split(\" \") #띄어쓰기를 단위로 tokenizing을 한다\n",
        "        if self.padding:#padding은, 위에 tokenizing을 선행적으로 해주고, 후에 해준다\n",
        "            tokenized_text += [self.pad_token] * (self.max_seq_length - len(tokenized_text))\n",
        "            return tokenized_text[:self.max_seq_length]#padding처리까지 해주고, max seq length만큼 잘라서 return해준다\n",
        "        else:\n",
        "            return tokenized_text[:self.max_seq_length]\n",
        "    def batch_tokenize(self, texts, tokenizer_type):#tokenizer도 batch단위로 작동하기 떄문에, batch에 대한 tokenizer를 생성\n",
        "        for i, text in enumerate(texts):\n",
        "            texts[i] = self.tokenize(text, tokenizer_type)\n",
        "        return texts"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9tAlYGv-OyzX"
      },
      "source": [
        "my_tokenizer = Tokenizer()\n",
        "my_tokenizer.pad_token = \"[PAD]\"\n",
        "my_tokenizer.max_seq_length = 10\n",
        "my_tokenizer.padding = True"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgkbR-L7O2Ap",
        "outputId": "9759279b-3daf-4894-b061-f40d6f16b84d"
      },
      "source": [
        "print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다.\", \"word\"))\n",
        "print(my_tokenizer.batch_tokenize([\"이순신은 조선 중기의 무신이다.\", \"그는 임진왜란을 승리로 이끌었다.\"], \"word\"))"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이순신은', '조선', '중기의', '무신이다.', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "[['이순신은', '조선', '중기의', '무신이다.', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]'], ['그는', '임진왜란을', '승리로', '이끌었다.', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6mUQBL0g9L6u"
      },
      "source": [
        "## 형태소 단위 tokenizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dx5kXtjS_3Ty"
      },
      "source": [
        "형태소 분석기로는 mecab을 사용하겠습니다.<br>\n",
        "konlpy와 mecab는 한국어 전처리 파일 꼭 참고"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3UhD2MyHACDA",
        "outputId": "cbfbd245-8f89-472d-9342-6959a655a3ca"
      },
      "source": [
        "!pip install konlpy"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting konlpy\n",
            "  Downloading konlpy-0.5.2-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 27.1 MB/s \n",
            "\u001b[?25hRequirement already satisfied: tweepy>=3.7.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (3.10.0)\n",
            "Collecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.3.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (448 kB)\n",
            "\u001b[K     |████████████████████████████████| 448 kB 47.0 MB/s \n",
            "\u001b[?25hCollecting beautifulsoup4==4.6.0\n",
            "  Downloading beautifulsoup4-4.6.0-py3-none-any.whl (86 kB)\n",
            "\u001b[K     |████████████████████████████████| 86 kB 5.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.19.5)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Collecting colorama\n",
            "  Downloading colorama-0.4.4-py2.py3-none-any.whl (16 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (3.7.4.3)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.15.0)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (1.3.0)\n",
            "Requirement already satisfied: requests[socks]>=2.11.1 in /usr/local/lib/python3.7/dist-packages (from tweepy>=3.7.0->konlpy) (2.23.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.7/dist-packages (from requests-oauthlib>=0.7.0->tweepy>=3.7.0->konlpy) (3.1.1)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2021.5.30)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (2.10)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.24.3)\n",
            "Requirement already satisfied: PySocks!=1.5.7,>=1.5.6 in /usr/local/lib/python3.7/dist-packages (from requests[socks]>=2.11.1->tweepy>=3.7.0->konlpy) (1.7.1)\n",
            "Installing collected packages: JPype1, colorama, beautifulsoup4, konlpy\n",
            "  Attempting uninstall: beautifulsoup4\n",
            "    Found existing installation: beautifulsoup4 4.6.3\n",
            "    Uninstalling beautifulsoup4-4.6.3:\n",
            "      Successfully uninstalled beautifulsoup4-4.6.3\n",
            "Successfully installed JPype1-1.3.0 beautifulsoup4-4.6.0 colorama-0.4.4 konlpy-0.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dWx_DISdAF5h",
        "outputId": "c3f6e725-74cd-437c-e685-8ac7f54875cf"
      },
      "source": [
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Installing automake (A dependency for mecab-ko)\n",
            "Ign:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:3 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:4 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:5 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Get:6 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [67.9 kB]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:12 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,428 kB]\n",
            "Get:14 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,351 kB]\n",
            "Get:15 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [594 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,203 kB]\n",
            "Hit:18 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:19 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:20 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:21 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,802 kB]\n",
            "Get:22 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [922 kB]\n",
            "Get:23 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [638 kB]\n",
            "Get:24 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [42.0 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [2,800 kB]\n",
            "Fetched 13.1 MB in 52s (252 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following additional packages will be installed:\n",
            "  autoconf autotools-dev libsigsegv2 m4\n",
            "Suggested packages:\n",
            "  autoconf-archive gnu-standards autoconf-doc libtool gettext m4-doc\n",
            "The following NEW packages will be installed:\n",
            "  autoconf automake autotools-dev libsigsegv2 m4\n",
            "0 upgraded, 5 newly installed, 0 to remove and 79 not upgraded.\n",
            "Need to get 1,082 kB of archives.\n",
            "After this operation, 3,994 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
            "Fetched 1,082 kB in 7s (163 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libsigsegv2:amd64.\n",
            "(Reading database ... 155013 files and directories currently installed.)\n",
            "Preparing to unpack .../libsigsegv2_2.12-1_amd64.deb ...\n",
            "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
            "Selecting previously unselected package m4.\n",
            "Preparing to unpack .../archives/m4_1.4.18-1_amd64.deb ...\n",
            "Unpacking m4 (1.4.18-1) ...\n",
            "Selecting previously unselected package autoconf.\n",
            "Preparing to unpack .../autoconf_2.69-11_all.deb ...\n",
            "Unpacking autoconf (2.69-11) ...\n",
            "Selecting previously unselected package autotools-dev.\n",
            "Preparing to unpack .../autotools-dev_20180224.1_all.deb ...\n",
            "Unpacking autotools-dev (20180224.1) ...\n",
            "Selecting previously unselected package automake.\n",
            "Preparing to unpack .../automake_1%3a1.15.1-3ubuntu2_all.deb ...\n",
            "Unpacking automake (1:1.15.1-3ubuntu2) ...\n",
            "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
            "Setting up m4 (1.4.18-1) ...\n",
            "Setting up autotools-dev (20180224.1) ...\n",
            "Setting up autoconf (2.69-11) ...\n",
            "Setting up automake (1:1.15.1-3ubuntu2) ...\n",
            "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Install mecab-ko-dic\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1381k  100 1381k    0     0   508k      0  0:00:02  0:00:02 --:--:-- 1247k\n",
            "mecab-0.996-ko-0.9.2/\n",
            "mecab-0.996-ko-0.9.2/example/\n",
            "mecab-0.996-ko-0.9.2/example/example.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.c\n",
            "mecab-0.996-ko-0.9.2/example/example.c\n",
            "mecab-0.996-ko-0.9.2/example/thread_test.cpp\n",
            "mecab-0.996-ko-0.9.2/mecab-config.in\n",
            "mecab-0.996-ko-0.9.2/man/\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/man/mecab.1\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/mecab.iss.in\n",
            "mecab-0.996-ko-0.9.2/config.guess\n",
            "mecab-0.996-ko-0.9.2/README\n",
            "mecab-0.996-ko-0.9.2/COPYING\n",
            "mecab-0.996-ko-0.9.2/CHANGES.md\n",
            "mecab-0.996-ko-0.9.2/README.md\n",
            "mecab-0.996-ko-0.9.2/INSTALL\n",
            "mecab-0.996-ko-0.9.2/config.sub\n",
            "mecab-0.996-ko-0.9.2/configure.in\n",
            "mecab-0.996-ko-0.9.2/swig/\n",
            "mecab-0.996-ko-0.9.2/swig/Makefile\n",
            "mecab-0.996-ko-0.9.2/swig/version.h.in\n",
            "mecab-0.996-ko-0.9.2/swig/version.h\n",
            "mecab-0.996-ko-0.9.2/swig/MeCab.i\n",
            "mecab-0.996-ko-0.9.2/aclocal.m4\n",
            "mecab-0.996-ko-0.9.2/LGPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/configure\n",
            "mecab-0.996-ko-0.9.2/tests/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/t9/\n",
            "mecab-0.996-ko-0.9.2/tests/t9/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/ipadic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test\n",
            "mecab-0.996-ko-0.9.2/tests/t9/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.train\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.test\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/rewrite.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/feature.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/run-eval.sh\n",
            "mecab-0.996-ko-0.9.2/tests/run-cost-train.sh\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/eval/\n",
            "mecab-0.996-ko-0.9.2/tests/eval/answer\n",
            "mecab-0.996-ko-0.9.2/tests/eval/system\n",
            "mecab-0.996-ko-0.9.2/tests/eval/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/latin/\n",
            "mecab-0.996-ko-0.9.2/tests/latin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test\n",
            "mecab-0.996-ko-0.9.2/tests/latin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/run-dics.sh\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/ltmain.sh\n",
            "mecab-0.996-ko-0.9.2/config.rpath\n",
            "mecab-0.996-ko-0.9.2/config.h.in\n",
            "mecab-0.996-ko-0.9.2/mecabrc.in\n",
            "mecab-0.996-ko-0.9.2/GPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.train\n",
            "mecab-0.996-ko-0.9.2/ChangeLog\n",
            "mecab-0.996-ko-0.9.2/install-sh\n",
            "mecab-0.996-ko-0.9.2/AUTHORS\n",
            "mecab-0.996-ko-0.9.2/doc/\n",
            "mecab-0.996-ko-0.9.2/doc/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/posid.html\n",
            "mecab-0.996-ko-0.9.2/doc/unk.html\n",
            "mecab-0.996-ko-0.9.2/doc/learn.html\n",
            "mecab-0.996-ko-0.9.2/doc/format.html\n",
            "mecab-0.996-ko-0.9.2/doc/libmecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.css\n",
            "mecab-0.996-ko-0.9.2/doc/feature.html\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/doc/soft.html\n",
            "mecab-0.996-ko-0.9.2/doc/en/\n",
            "mecab-0.996-ko-0.9.2/doc/en/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic-detail.html\n",
            "mecab-0.996-ko-0.9.2/doc/flow.png\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/result.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_a.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_eval.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_vars.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_r.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h_source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tabs.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_f.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/closed.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_l.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaces.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaceMeCab.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/files.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/annotated.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_defs.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classes.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h-source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/bc_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/open.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic.html\n",
            "mecab-0.996-ko-0.9.2/doc/partial.html\n",
            "mecab-0.996-ko-0.9.2/doc/feature.png\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/missing\n",
            "mecab-0.996-ko-0.9.2/BSD\n",
            "mecab-0.996-ko-0.9.2/NEWS\n",
            "mecab-0.996-ko-0.9.2/mkinstalldirs\n",
            "mecab-0.996-ko-0.9.2/src/\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.h\n",
            "mecab-0.996-ko-0.9.2/src/utils.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/make.bat\n",
            "mecab-0.996-ko-0.9.2/src/mecab.h\n",
            "mecab-0.996-ko-0.9.2/src/freelist.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_compiler.cpp\n",
            "mecab-0.996-ko-0.9.2/src/eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-system-eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/darts.h\n",
            "mecab-0.996-ko-0.9.2/src/param.h\n",
            "mecab-0.996-ko-0.9.2/src/char_property.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_node.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/winmain.h\n",
            "mecab-0.996-ko-0.9.2/src/thread.h\n",
            "mecab-0.996-ko-0.9.2/src/context_id.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/src/connector.h\n",
            "mecab-0.996-ko-0.9.2/src/common.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.msvc.in\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.h\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/char_property.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-test-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-cost-train.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.cpp\n",
            "mecab-0.996-ko-0.9.2/src/ucs.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.h\n",
            "mecab-0.996-ko-0.9.2/src/libmecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/param.cpp\n",
            "mecab-0.996-ko-0.9.2/src/context_id.h\n",
            "mecab-0.996-ko-0.9.2/src/mmap.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.cpp\n",
            "mecab-0.996-ko-0.9.2/src/stream_wrapper.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.h\n",
            "mecab-0.996-ko-0.9.2/src/ucstable.h\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.h\n",
            "mecab-0.996-ko-0.9.2/src/connector.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/src/scoped_ptr.h\n",
            "mecab-0.996-ko-0.9.2/Makefile.in\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for gcc... gcc\n",
            "checking whether the C compiler works... yes\n",
            "checking for C compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking for style of include used by make... GNU\n",
            "checking dependency style of gcc... none\n",
            "checking for g++... g++\n",
            "checking whether we are using the GNU C++ compiler... yes\n",
            "checking whether g++ accepts -g... yes\n",
            "checking dependency style of g++... none\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for grep that handles long lines and -e... /bin/grep\n",
            "checking for egrep... /bin/grep -E\n",
            "checking whether gcc needs -traditional... no\n",
            "checking whether make sets $(MAKE)... (cached) yes\n",
            "checking build system type... x86_64-unknown-linux-gnu\n",
            "checking host system type... x86_64-unknown-linux-gnu\n",
            "checking how to print strings... printf\n",
            "checking for a sed that does not truncate output... /bin/sed\n",
            "checking for fgrep... /bin/grep -F\n",
            "checking for ld used by gcc... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
            "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
            "checking whether ln -s works... yes\n",
            "checking the maximum length of command line arguments... 1572864\n",
            "checking whether the shell understands some XSI constructs... yes\n",
            "checking whether the shell understands \"+=\"... yes\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
            "checking for /usr/bin/ld option to reload object files... -r\n",
            "checking for objdump... objdump\n",
            "checking how to recognize dependent libraries... pass_all\n",
            "checking for dlltool... dlltool\n",
            "checking how to associate runtime and link libraries... printf %s\\n\n",
            "checking for ar... ar\n",
            "checking for archiver @FILE support... @\n",
            "checking for strip... strip\n",
            "checking for ranlib... ranlib\n",
            "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
            "checking for sysroot... no\n",
            "./configure: line 7378: /usr/bin/file: No such file or directory\n",
            "checking for mt... no\n",
            "checking if : is a manifest tool... no\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking for dlfcn.h... yes\n",
            "checking for objdir... .libs\n",
            "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
            "checking for gcc option to produce PIC... -fPIC -DPIC\n",
            "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
            "checking if gcc static flag -static works... yes\n",
            "checking if gcc supports -c -o file.o... yes\n",
            "checking if gcc supports -c -o file.o... (cached) yes\n",
            "checking whether the gcc linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking whether -lc should be explicitly linked in... no\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking whether stripping libraries is possible... yes\n",
            "checking if libtool supports shared libraries... yes\n",
            "checking whether to build shared libraries... yes\n",
            "checking whether to build static libraries... yes\n",
            "checking how to run the C++ preprocessor... g++ -E\n",
            "checking for ld used by g++... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking for g++ option to produce PIC... -fPIC -DPIC\n",
            "checking if g++ PIC flag -fPIC -DPIC works... yes\n",
            "checking if g++ static flag -static works... yes\n",
            "checking if g++ supports -c -o file.o... yes\n",
            "checking if g++ supports -c -o file.o... (cached) yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking for library containing strerror... none required\n",
            "checking whether byte ordering is bigendian... no\n",
            "checking for ld used by GCC... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for shared library run path origin... done\n",
            "checking for iconv... yes\n",
            "checking for working iconv... yes\n",
            "checking for iconv declaration... \n",
            "         extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);\n",
            "checking for ANSI C header files... (cached) yes\n",
            "checking for an ANSI C-conforming const... yes\n",
            "checking whether byte ordering is bigendian... (cached) no\n",
            "checking for string.h... (cached) yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking fcntl.h usability... yes\n",
            "checking fcntl.h presence... yes\n",
            "checking for fcntl.h... yes\n",
            "checking for stdint.h... (cached) yes\n",
            "checking for sys/stat.h... (cached) yes\n",
            "checking sys/mman.h usability... yes\n",
            "checking sys/mman.h presence... yes\n",
            "checking for sys/mman.h... yes\n",
            "checking sys/times.h usability... yes\n",
            "checking sys/times.h presence... yes\n",
            "checking for sys/times.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking dirent.h usability... yes\n",
            "checking dirent.h presence... yes\n",
            "checking for dirent.h... yes\n",
            "checking ctype.h usability... yes\n",
            "checking ctype.h presence... yes\n",
            "checking for ctype.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking io.h usability... no\n",
            "checking io.h presence... no\n",
            "checking for io.h... no\n",
            "checking windows.h usability... no\n",
            "checking windows.h presence... no\n",
            "checking for windows.h... no\n",
            "checking pthread.h usability... yes\n",
            "checking pthread.h presence... yes\n",
            "checking for pthread.h... yes\n",
            "checking for off_t... yes\n",
            "checking for size_t... yes\n",
            "checking size of char... 1\n",
            "checking size of short... 2\n",
            "checking size of int... 4\n",
            "checking size of long... 8\n",
            "checking size of long long... 8\n",
            "checking size of size_t... 8\n",
            "checking for size_t... (cached) yes\n",
            "checking for unsigned long long int... yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking for sys/param.h... yes\n",
            "checking for getpagesize... yes\n",
            "checking for working mmap... yes\n",
            "checking for main in -lstdc++... yes\n",
            "checking for pthread_create in -lpthread... yes\n",
            "checking for pthread_join in -lpthread... yes\n",
            "checking for getenv... yes\n",
            "checking for opendir... yes\n",
            "checking whether make is GNU Make... yes\n",
            "checking if g++ supports stl <vector> (required)... yes\n",
            "checking if g++ supports stl <list> (required)... yes\n",
            "checking if g++ supports stl <map> (required)... yes\n",
            "checking if g++ supports stl <set> (required)... yes\n",
            "checking if g++ supports stl <queue> (required)... yes\n",
            "checking if g++ supports stl <functional> (required)... yes\n",
            "checking if g++ supports stl <algorithm> (required)... yes\n",
            "checking if g++ supports stl <string> (required)... yes\n",
            "checking if g++ supports stl <iostream> (required)... yes\n",
            "checking if g++ supports stl <sstream> (required)... yes\n",
            "checking if g++ supports stl <fstream> (required)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports const_cast<> (required)... yes\n",
            "checking if g++ supports static_cast<> (required)... yes\n",
            "checking if g++ supports reinterpret_cast<> (required)... yes\n",
            "checking if g++ supports namespaces (required) ... yes\n",
            "checking if g++ supports __thread (optional)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports GCC native atomic operations (optional)... yes\n",
            "checking if g++ supports OSX native atomic operations (optional)... no\n",
            "checking if g++ environment provides all required features... yes\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "config.status: creating src/Makefile\n",
            "config.status: creating src/Makefile.msvc\n",
            "config.status: creating man/Makefile\n",
            "config.status: creating doc/Makefile\n",
            "config.status: creating tests/Makefile\n",
            "config.status: creating swig/version.h\n",
            "config.status: creating mecab.iss\n",
            "config.status: creating mecab-config\n",
            "config.status: creating mecabrc\n",
            "config.status: creating config.h\n",
            "config.status: executing depfiles commands\n",
            "config.status: executing libtool commands\n",
            "config.status: executing default commands\n",
            "make  all-recursive\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making all in src\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o viterbi.lo viterbi.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp  -fPIC -DPIC -o .libs/viterbi.o\n",
            "In file included from \u001b[01m\u001b[Kviterbi.cpp:14:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kparam.h:30:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[KTarget {anonymous}::lexical_cast(Source) [with Target = std::__cxx11::basic_string<char>; Source = std::__cxx11::basic_string<char>]\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " std::string \u001b[01;35m\u001b[Klexical_cast<std::string, std::string>\u001b[m\u001b[K(std::string arg) {\n",
            "             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp -o viterbi.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tagger.lo tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp  -fPIC -DPIC -o .libs/tagger.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp -o tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o utils.lo utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp  -fPIC -DPIC -o .libs/utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp -o utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o eval.lo eval.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp  -fPIC -DPIC -o .libs/eval.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp -o eval.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o iconv_utils.lo iconv_utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp  -fPIC -DPIC -o .libs/iconv_utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp -o iconv_utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_rewriter.lo dictionary_rewriter.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp  -fPIC -DPIC -o .libs/dictionary_rewriter.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp -o dictionary_rewriter.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_generator.lo dictionary_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp  -fPIC -DPIC -o .libs/dictionary_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp -o dictionary_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_compiler.lo dictionary_compiler.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp  -fPIC -DPIC -o .libs/dictionary_compiler.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp -o dictionary_compiler.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o context_id.lo context_id.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp  -fPIC -DPIC -o .libs/context_id.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp -o context_id.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o connector.lo connector.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp  -fPIC -DPIC -o .libs/connector.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp -o connector.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o nbest_generator.lo nbest_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp  -fPIC -DPIC -o .libs/nbest_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp -o nbest_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o writer.lo writer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp  -fPIC -DPIC -o .libs/writer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp -o writer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o string_buffer.lo string_buffer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp  -fPIC -DPIC -o .libs/string_buffer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp -o string_buffer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o param.lo param.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp  -fPIC -DPIC -o .libs/param.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp -o param.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tokenizer.lo tokenizer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp  -fPIC -DPIC -o .libs/tokenizer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp -o tokenizer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o char_property.lo char_property.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp  -fPIC -DPIC -o .libs/char_property.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp -o char_property.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary.lo dictionary.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp  -fPIC -DPIC -o .libs/dictionary.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp -o dictionary.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o feature_index.lo feature_index.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp  -fPIC -DPIC -o .libs/feature_index.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp -o feature_index.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o lbfgs.lo lbfgs.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp  -fPIC -DPIC -o .libs/lbfgs.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp -o lbfgs.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner_tagger.lo learner_tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp  -fPIC -DPIC -o .libs/learner_tagger.o\n",
            "\u001b[01m\u001b[Klearner_tagger.cpp:25:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[Kchar* MeCab::{anonymous}::mystrdup(const string&)\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " char *\u001b[01;35m\u001b[Kmystrdup\u001b[m\u001b[K(const std::string &str) {\n",
            "       \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp -o learner_tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner.lo learner.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp  -fPIC -DPIC -o .libs/learner.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp -o learner.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o libmecab.lo libmecab.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp  -fPIC -DPIC -o .libs/libmecab.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp -o libmecab.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall  -no-undefined -version-info 2:0:0  -o libmecab.la -rpath /usr/local/lib viterbi.lo tagger.lo utils.lo eval.lo iconv_utils.lo dictionary_rewriter.lo dictionary_generator.lo dictionary_compiler.lo context_id.lo connector.lo nbest_generator.lo writer.lo string_buffer.lo param.lo tokenizer.lo char_property.lo dictionary.lo feature_index.lo lbfgs.lo learner_tagger.lo learner.lo libmecab.lo  -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o  .libs/viterbi.o .libs/tagger.o .libs/utils.o .libs/eval.o .libs/iconv_utils.o .libs/dictionary_rewriter.o .libs/dictionary_generator.o .libs/dictionary_compiler.o .libs/context_id.o .libs/connector.o .libs/nbest_generator.o .libs/writer.o .libs/string_buffer.o .libs/param.o .libs/tokenizer.o .libs/char_property.o .libs/dictionary.o .libs/feature_index.o .libs/lbfgs.o .libs/learner_tagger.o .libs/learner.o .libs/libmecab.o   -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/7/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o  -O3   -Wl,-soname -Wl,libmecab.so.2 -o .libs/libmecab.so.2.0.0\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so.2\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so.2\")\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so\")\n",
            "libtool: link: ar cru .libs/libmecab.a  viterbi.o tagger.o utils.o eval.o iconv_utils.o dictionary_rewriter.o dictionary_generator.o dictionary_compiler.o context_id.o connector.o nbest_generator.o writer.o string_buffer.o param.o tokenizer.o char_property.o dictionary.o feature_index.o lbfgs.o learner_tagger.o learner.o libmecab.o\n",
            "ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "libtool: link: ranlib .libs/libmecab.a\n",
            "libtool: link: ( cd \".libs\" && rm -f \"libmecab.la\" && ln -s \"../libmecab.la\" \"libmecab.la\" )\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab.o mecab.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab mecab.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab mecab.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-index.o mecab-dict-index.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-index mecab-dict-index.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-index mecab-dict-index.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-gen.o mecab-dict-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-gen mecab-dict-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-gen mecab-dict-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-cost-train.o mecab-cost-train.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-cost-train mecab-cost-train.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-cost-train mecab-cost-train.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-system-eval.o mecab-system-eval.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-system-eval mecab-system-eval.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-system-eval mecab-system-eval.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-test-gen.o mecab-test-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-test-gen mecab-test-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-test-gen mecab-test-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making all in man\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making all in doc\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making all in tests\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making check in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making check in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making check in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making check in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make  check-TESTS\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 177\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 178x178\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 83\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 84x84\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 450\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 162\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3x3\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 4\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 11\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "PASS: run-dics.sh\n",
            "PASS: run-eval.sh\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "seed/model.def is not found. skipped.\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading seed/matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "reading corpus ...\n",
            "Number of sentences: 34\n",
            "Number of features:  64108\n",
            "eta:                 0.00005\n",
            "freq:                1\n",
            "eval-size:           6\n",
            "unk-eval-size:       4\n",
            "threads:             1\n",
            "charset:             EUC-JP\n",
            "C(sigma^2):          1.00000\n",
            "\n",
            "iter=0 err=1.00000 F=0.35771 target=2406.28355 diff=1.00000\n",
            "iter=1 err=0.97059 F=0.65652 target=1484.25231 diff=0.38318\n",
            "iter=2 err=0.91176 F=0.79331 target=863.32765 diff=0.41834\n",
            "iter=3 err=0.85294 F=0.89213 target=596.72480 diff=0.30881\n",
            "iter=4 err=0.61765 F=0.95467 target=336.30744 diff=0.43641\n",
            "iter=5 err=0.50000 F=0.96702 target=246.53039 diff=0.26695\n",
            "iter=6 err=0.35294 F=0.95472 target=188.93963 diff=0.23361\n",
            "iter=7 err=0.20588 F=0.99106 target=168.62665 diff=0.10751\n",
            "iter=8 err=0.05882 F=0.99777 target=158.64865 diff=0.05917\n",
            "iter=9 err=0.08824 F=0.99665 target=154.14530 diff=0.02839\n",
            "iter=10 err=0.08824 F=0.99665 target=151.94257 diff=0.01429\n",
            "iter=11 err=0.02941 F=0.99888 target=147.20825 diff=0.03116\n",
            "iter=12 err=0.00000 F=1.00000 target=147.34956 diff=0.00096\n",
            "iter=13 err=0.02941 F=0.99888 target=146.32592 diff=0.00695\n",
            "iter=14 err=0.00000 F=1.00000 target=145.77299 diff=0.00378\n",
            "iter=15 err=0.02941 F=0.99888 target=145.24641 diff=0.00361\n",
            "iter=16 err=0.00000 F=1.00000 target=144.96490 diff=0.00194\n",
            "iter=17 err=0.02941 F=0.99888 target=144.90246 diff=0.00043\n",
            "iter=18 err=0.00000 F=1.00000 target=144.75959 diff=0.00099\n",
            "iter=19 err=0.00000 F=1.00000 target=144.71727 diff=0.00029\n",
            "iter=20 err=0.00000 F=1.00000 target=144.66337 diff=0.00037\n",
            "iter=21 err=0.00000 F=1.00000 target=144.61349 diff=0.00034\n",
            "iter=22 err=0.00000 F=1.00000 target=144.62987 diff=0.00011\n",
            "iter=23 err=0.00000 F=1.00000 target=144.60060 diff=0.00020\n",
            "iter=24 err=0.00000 F=1.00000 target=144.59125 diff=0.00006\n",
            "iter=25 err=0.00000 F=1.00000 target=144.58619 diff=0.00004\n",
            "iter=26 err=0.00000 F=1.00000 target=144.58219 diff=0.00003\n",
            "iter=27 err=0.00000 F=1.00000 target=144.58059 diff=0.00001\n",
            "\n",
            "Done! writing model file ... \n",
            "model-ipadic.c1.0.f1.model is not a binary model. reopen it as text mode...\n",
            "reading seed/unk.def ... 40\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting model-ipadic.c1.0.f1.dic/left-id.def/ model-ipadic.c1.0.f1.dic/right-id.def\n",
            "emitting model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting matrix      : 100% |###########################################| \n",
            "copying seed/char.def to model-ipadic.c1.0.f1.dic/char.def\n",
            "copying seed/rewrite.def to model-ipadic.c1.0.f1.dic/rewrite.def\n",
            "copying seed/dicrc to model-ipadic.c1.0.f1.dic/dicrc\n",
            "copying seed/feature.def to model-ipadic.c1.0.f1.dic/feature.def\n",
            "copying model-ipadic.c1.0.f1.model to model-ipadic.c1.0.f1.dic/model.def\n",
            "\n",
            "done!\n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading model-ipadic.c1.0.f1.dic/matrix.def ... 346x346\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "              precision          recall         F\n",
            "LEVEL 0:    12.8959(57/442) 11.8998(57/479) 12.3779\n",
            "LEVEL 1:    12.2172(54/442) 11.2735(54/479) 11.7264\n",
            "LEVEL 2:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "LEVEL 4:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "PASS: run-cost-train.sh\n",
            "==================\n",
            "All 3 tests passed\n",
            "==================\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making install in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "test -z \"/usr/local/lib\" || /bin/mkdir -p \"/usr/local/lib\"\n",
            " /bin/bash ../libtool   --mode=install /usr/bin/install -c   libmecab.la '/usr/local/lib'\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.so.2.0.0 /usr/local/lib/libmecab.so.2.0.0\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so.2 || { rm -f libmecab.so.2 && ln -s libmecab.so.2.0.0 libmecab.so.2; }; })\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so || { rm -f libmecab.so && ln -s libmecab.so.2.0.0 libmecab.so; }; })\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.lai /usr/local/lib/libmecab.la\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.a /usr/local/lib/libmecab.a\n",
            "libtool: install: chmod 644 /usr/local/lib/libmecab.a\n",
            "libtool: install: ranlib /usr/local/lib/libmecab.a\n",
            "libtool: finish: PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/sbin\" ldconfig -n /usr/local/lib\n",
            "----------------------------------------------------------------------\n",
            "Libraries have been installed in:\n",
            "   /usr/local/lib\n",
            "\n",
            "If you ever happen to want to link against installed libraries\n",
            "in a given directory, LIBDIR, you must either use libtool, and\n",
            "specify the full pathname of the library, or use the `-LLIBDIR'\n",
            "flag during linking and do at least one of the following:\n",
            "   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
            "     during execution\n",
            "   - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
            "     during linking\n",
            "   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
            "   - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
            "\n",
            "See any operating system documentation about shared libraries for\n",
            "more information, such as the ld(1) and ld.so(8) manual pages.\n",
            "----------------------------------------------------------------------\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab '/usr/local/bin'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab /usr/local/bin/mecab\n",
            "test -z \"/usr/local/libexec/mecab\" || /bin/mkdir -p \"/usr/local/libexec/mecab\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab-dict-index mecab-dict-gen mecab-cost-train mecab-system-eval mecab-test-gen '/usr/local/libexec/mecab'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-index /usr/local/libexec/mecab/mecab-dict-index\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-gen /usr/local/libexec/mecab/mecab-dict-gen\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-cost-train /usr/local/libexec/mecab/mecab-cost-train\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-system-eval /usr/local/libexec/mecab/mecab-system-eval\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-test-gen /usr/local/libexec/mecab/mecab-test-gen\n",
            "test -z \"/usr/local/include\" || /bin/mkdir -p \"/usr/local/include\"\n",
            " /usr/bin/install -c -m 644 mecab.h '/usr/local/include'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making install in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "test -z \"/usr/local/share/man/man1\" || /bin/mkdir -p \"/usr/local/share/man/man1\"\n",
            " /usr/bin/install -c -m 644 mecab.1 '/usr/local/share/man/man1'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making install in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making install in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            " /usr/bin/install -c mecab-config '/usr/local/bin'\n",
            "test -z \"/usr/local/etc\" || /bin/mkdir -p \"/usr/local/etc\"\n",
            " /usr/bin/install -c -m 644 mecabrc '/usr/local/etc'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Install mecab-ko-dic\n",
            "Install mecab-ko-dic\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 47.4M  100 47.4M    0     0  7510k      0  0:00:06  0:00:06 --:--:--  9.8M\n",
            "mecab-ko-dic-2.1.1-20180720/\n",
            "mecab-ko-dic-2.1.1-20180720/configure\n",
            "mecab-ko-dic-2.1.1-20180720/COPYING\n",
            "mecab-ko-dic-2.1.1-20180720/autogen.sh\n",
            "mecab-ko-dic-2.1.1-20180720/Place-station.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/README\n",
            "mecab-ko-dic-2.1.1-20180720/EF.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Preanalysis.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNB.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Person-actor.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.in\n",
            "mecab-ko-dic-2.1.1-20180720/matrix.def\n",
            "mecab-ko-dic-2.1.1-20180720/EC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNBC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/clean\n",
            "mecab-ko-dic-2.1.1-20180720/ChangeLog\n",
            "mecab-ko-dic-2.1.1-20180720/J.csv\n",
            "mecab-ko-dic-2.1.1-20180720/.keep\n",
            "mecab-ko-dic-2.1.1-20180720/feature.def\n",
            "mecab-ko-dic-2.1.1-20180720/Foreign.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XPN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/EP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/left-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Symbol.csv\n",
            "mecab-ko-dic-2.1.1-20180720/dicrc\n",
            "mecab-ko-dic-2.1.1-20180720/NP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/IC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Place-address.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Group.csv\n",
            "mecab-ko-dic-2.1.1-20180720/model.def\n",
            "mecab-ko-dic-2.1.1-20180720/XSN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/INSTALL\n",
            "mecab-ko-dic-2.1.1-20180720/rewrite.def\n",
            "mecab-ko-dic-2.1.1-20180720/Inflect.csv\n",
            "mecab-ko-dic-2.1.1-20180720/configure.ac\n",
            "mecab-ko-dic-2.1.1-20180720/NNP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/CoinedWord.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/pos-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.am\n",
            "mecab-ko-dic-2.1.1-20180720/unk.def\n",
            "mecab-ko-dic-2.1.1-20180720/missing\n",
            "mecab-ko-dic-2.1.1-20180720/VCP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/install-sh\n",
            "mecab-ko-dic-2.1.1-20180720/Hanja.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAJ.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Wikipedia.csv\n",
            "mecab-ko-dic-2.1.1-20180720/tools/\n",
            "mecab-ko-dic-2.1.1-20180720/tools/add-userdic.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/mecab-bestn.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/convert_for_using_store.sh\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/README.md\n",
            "mecab-ko-dic-2.1.1-20180720/NorthKorea.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VX.csv\n",
            "mecab-ko-dic-2.1.1-20180720/right-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/VA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/char.def\n",
            "mecab-ko-dic-2.1.1-20180720/NEWS\n",
            "mecab-ko-dic-2.1.1-20180720/MM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/AUTHORS\n",
            "mecab-ko-dic-2.1.1-20180720/Person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VCN.csv\n",
            "Looking in current directory for macros.\n",
            "configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\n",
            "configure.ac:2: http://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720/missing: Unknown `--is-lightweight' option\n",
            "Try `/tmp/mecab-ko-dic-2.1.1-20180720/missing --help' for more information\n",
            "configure: WARNING: 'missing' script is too old or missing\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking whether make supports nested variables... yes\n",
            "checking for mecab-config... /usr/local/bin/mecab-config\n",
            "checking that generated files are newer than configure... done\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "/usr/local/lib\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n",
            "reading ./unk.def ... 13\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./EF.csv ... 1820\n",
            "reading ./Place-station.csv ... 1145\n",
            "reading ./NNG.csv ... 208524\n",
            "reading ./IC.csv ... 1305\n",
            "reading ./J.csv ... 416\n",
            "reading ./Group.csv ... 3176\n",
            "reading ./VCP.csv ... 9\n",
            "reading ./NNP.csv ... 2371\n",
            "reading ./Person-actor.csv ... 99230\n",
            "reading ./Person.csv ... 196459\n",
            "reading ./CoinedWord.csv ... 148\n",
            "reading ./Wikipedia.csv ... 36762\n",
            "reading ./NNBC.csv ... 677\n",
            "reading ./VV.csv ... 7331\n",
            "reading ./Hanja.csv ... 125750\n",
            "reading ./XSA.csv ... 19\n",
            "reading ./MAG.csv ... 14242\n",
            "reading ./NP.csv ... 342\n",
            "reading ./NorthKorea.csv ... 3\n",
            "reading ./VX.csv ... 125\n",
            "reading ./EP.csv ... 51\n",
            "reading ./Place-address.csv ... 19301\n",
            "reading ./ETN.csv ... 14\n",
            "reading ./XSV.csv ... 23\n",
            "reading ./Inflect.csv ... 44820\n",
            "reading ./Place.csv ... 30303\n",
            "reading ./EC.csv ... 2547\n",
            "reading ./XPN.csv ... 83\n",
            "reading ./NR.csv ... 482\n",
            "reading ./NNB.csv ... 140\n",
            "reading ./Foreign.csv ... 11690\n",
            "reading ./ETM.csv ... 133\n",
            "reading ./XSN.csv ... 124\n",
            "reading ./Preanalysis.csv ... 5\n",
            "reading ./MAJ.csv ... 240\n",
            "reading ./MM.csv ... 453\n",
            "reading ./VCN.csv ... 7\n",
            "reading ./VA.csv ... 2360\n",
            "reading ./Symbol.csv ... 16\n",
            "reading ./XR.csv ... 3637\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3822x2693\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "echo To enable dictionary, rewrite /usr/local/etc/mecabrc as \\\"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\\\"\n",
            "To enable dictionary, rewrite /usr/local/etc/mecabrc as \"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\"\n",
            "make[1]: Entering directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "make[1]: Nothing to be done for 'install-exec-am'.\n",
            " /bin/mkdir -p '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            " /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            "make[1]: Leaving directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "Install mecab-python\n",
            "/tmp /tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Cloning into 'mecab-python-0.996'...\n",
            "Unpacking objects: 100% (17/17), done.\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Processing /tmp/mecab-python-0.996\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Building wheels for collected packages: mecab-python\n",
            "  Building wheel for mecab-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp37-cp37m-linux_x86_64.whl size=141810 sha256=83c105cf0dd85888445bf3f855feabbafcdfda45a7be8ebaa9790f881e53cd0b\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/7b/9f/2922869bef86c3354ae7034f7a3647c573ee1997c2dad0290a\n",
            "\u001b[33m  WARNING: Built wheel for mecab-python is invalid: Metadata 1.2 mandates PEP 440 version, but '0.996-ko-0.9.2' is not\u001b[0m\n",
            "Failed to build mecab-python\n",
            "Installing collected packages: mecab-python\n",
            "    Running setup.py install for mecab-python ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: mecab-python was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n",
            "Successfully installed mecab-python-0.996-ko-0.9.2\n",
            "Done.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "af79UYHWATYj",
        "outputId": "788dca21-590c-45d9-b0e9-82d43ffcbc9f"
      },
      "source": [
        "from konlpy.tag import Mecab\n",
        "\n",
        "mecab = Mecab()\n",
        "print(mecab.pos(\"아버지가방에들어가신다.\"))"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[('아버지', 'NNG'), ('가', 'JKS'), ('방', 'NNG'), ('에', 'JKB'), ('들어가', 'VV'), ('신다', 'EP+EF'), ('.', 'SF')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vzxy7U6oAtCE",
        "outputId": "4c2aff03-ec51-438b-e21b-48df917296a5"
      },
      "source": [
        "text = \"이순신은 조선 중기의 무신이다.\"\n",
        "# 이순신 -> PS\n",
        "# 조선 -> DT TI\n",
        "# 중기 -> TI\n",
        "# 무신 -> OC\n",
        "# 이순신 - 직업 - 무신\n",
        "# 이순신 - 출생지 - 조선\n",
        "\n",
        "tokenized_text = [lemma[0] for lemma in mecab.pos(text)]\n",
        "print(tokenized_text)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이순신', '은', '조선', '중기', '의', '무신', '이', '다', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RN6sNjOICGng"
      },
      "source": [
        "형태소 tokenizer도 class에 추가하겠습니다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tCuEuxtNkkgt"
      },
      "source": [
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RYhBL-VpCF6O"
      },
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self):\n",
        "        self.tokenizer_type_list = [\"word\", \"morph\"]\n",
        "        self.pad_token = \"<pad>\"\n",
        "        self.max_seq_length = 10\n",
        "        self.padding = False\n",
        "    def tokenize(self, text, tokenizer_type): \n",
        "        assert tokenizer_type in self.tokenizer_type_list, \"정의되지 않은 tokenizer_type입니다.\"\n",
        "        if tokenizer_type == \"word\":\n",
        "            tokenized_text = text.split(\" \")\n",
        "        elif tokenizer_type == \"morph\":\n",
        "            tokenized_text = [lemma[0] for lemma in mecab.pos(text)]#!!!!위에 그림 참고!!!!\n",
        "        if self.padding:\n",
        "            tokenized_text += [self.pad_token] * (self.max_seq_length - len(tokenized_text))\n",
        "            return tokenized_text[:self.max_seq_length]\n",
        "        else:\n",
        "            return tokenized_text[:self.max_seq_length]\n",
        "    def batch_tokenize(self, texts, tokenizer_type):\n",
        "        for i, text in enumerate(texts):\n",
        "            texts[i] = self.tokenize(text, tokenizer_type)\n",
        "        return texts"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fMas8FOVF94u"
      },
      "source": [
        "my_tokenizer = Tokenizer()\n",
        "my_tokenizer.pad_token = \"[PAD]\"\n",
        "my_tokenizer.max_seq_length = 10\n",
        "my_tokenizer.padding = True"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1NJ5PgGoCSie",
        "outputId": "a80a4204-0f43-4dd8-92c7-0fb1496455a5"
      },
      "source": [
        "print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다.\", \"morph\"))\n",
        "print(my_tokenizer.batch_tokenize([\"이순신은 조선 중기의 무신이다.\", \"그는 임진왜란을 승리로 이끌었다.\"], \"morph\"))"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이순신', '은', '조선', '중기', '의', '무신', '이', '다', '.', '[PAD]']\n",
            "[['이순신', '은', '조선', '중기', '의', '무신', '이', '다', '.', '[PAD]'], ['그', '는', '임진왜란', '을', '승리', '로', '이끌', '었', '다', '.']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ta-DT6gdbjwB"
      },
      "source": [
        "## 음절 단위 tokenizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "--hnlgWmCaCm"
      },
      "source": [
        "음절 단위 tokenizing은 한 자연어를 한 글자씩 분리합니다.<br>\n",
        "이건 그냥 list(문장) 씌워주면 알아서 한 글자씩 분리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rV8SNdlxb_GS",
        "outputId": "7fa30e90-89c6-487b-80c4-25b4a3f4c0a4"
      },
      "source": [
        "text = \"이순신은 조선 중기의 무신이다.\"\n",
        "tokenized_text = list(text)    # split 함수는 입력 string에 대해서 특정 string을 기반으로 분리해줍니다.\n",
        "print(tokenized_text)  "
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이', '순', '신', '은', ' ', '조', '선', ' ', '중', '기', '의', ' ', '무', '신', '이', '다', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "H7fr-5HN-7Yx"
      },
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self):\n",
        "        self.tokenizer_type_list = [\"word\", \"morph\", \"syllable\"]\n",
        "        self.pad_token = \"<pad>\"\n",
        "        self.max_seq_length = 10\n",
        "        self.padding = False\n",
        "    def tokenize(self, text, tokenizer_type): \n",
        "        assert tokenizer_type in self.tokenizer_type_list, \"정의되지 않은 tokenizer_type입니다.\"\n",
        "        if tokenizer_type == \"word\":\n",
        "            tokenized_text = text.split(\" \")\n",
        "        elif tokenizer_type == \"morph\":\n",
        "            tokenized_text = [lemma[0] for lemma in mecab.pos(text)]\n",
        "        elif tokenizer_type == \"syllable\":\n",
        "            tokenized_text = list(text)\n",
        "        if self.padding:\n",
        "            tokenized_text += [self.pad_token] * (self.max_seq_length - len(tokenized_text))\n",
        "            return tokenized_text[:self.max_seq_length]\n",
        "        else:\n",
        "            return tokenized_text[:self.max_seq_length]\n",
        "    def batch_tokenize(self, texts, tokenizer_type):\n",
        "        for i, text in enumerate(texts):\n",
        "            texts[i] = self.tokenize(text, tokenizer_type)\n",
        "        return texts"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4udPQal-_s_M"
      },
      "source": [
        "my_tokenizer = Tokenizer()\n",
        "my_tokenizer.pad_token = \"[PAD]\"\n",
        "my_tokenizer.max_seq_length = 20\n",
        "my_tokenizer.padding = True"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xXcB2P1j_vdk",
        "outputId": "941f0a1d-b56e-459c-d74b-0663baf4043f"
      },
      "source": [
        "print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다.\", \"syllable\"))\n",
        "print(my_tokenizer.batch_tokenize([\"이순신은 조선 중기의 무신이다.\", \"그는 임진왜란을 승리로 이끌었다.\"], \"syllable\"))"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이', '순', '신', '은', ' ', '조', '선', ' ', '중', '기', '의', ' ', '무', '신', '이', '다', '.', '[PAD]', '[PAD]', '[PAD]']\n",
            "[['이', '순', '신', '은', ' ', '조', '선', ' ', '중', '기', '의', ' ', '무', '신', '이', '다', '.', '[PAD]', '[PAD]', '[PAD]'], ['그', '는', ' ', '임', '진', '왜', '란', '을', ' ', '승', '리', '로', ' ', '이', '끌', '었', '다', '.', '[PAD]', '[PAD]']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ruy_UuG8DA5t"
      },
      "source": [
        "## 자소 단위 tokenizing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S5InCTAaDESD"
      },
      "source": [
        "한글은 하나의 문자도 최대 초성, 중성, 종성, 총 3개의 자소로 분리가 가능합니다.   \n",
        "실습에서는 자소 분리를 위해 hgtk 라이브러리를 사용하겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WzhVFKORDQSu",
        "outputId": "7b95855f-1219-4a8f-da41-035d637b3bf8"
      },
      "source": [
        "!pip install hgtk"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting hgtk\n",
            "  Downloading hgtk-0.1.3.tar.gz (6.2 kB)\n",
            "Building wheels for collected packages: hgtk\n",
            "  Building wheel for hgtk (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for hgtk: filename=hgtk-0.1.3-py2.py3-none-any.whl size=6689 sha256=1edad9adc4b0bf9f75145c55aca2d9dfe745ea61e1efd9bbc5c14d15e0f08183\n",
            "  Stored in directory: /root/.cache/pip/wheels/a6/e9/bc/524beb5222b11aa439a23a07be5bd8a559d266153103c37979\n",
            "Successfully built hgtk\n",
            "Installing collected packages: hgtk\n",
            "Successfully installed hgtk-0.1.3\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2o0uPPtDzUf"
      },
      "source": [
        "import hgtk"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fIv84Y-IDnV1",
        "outputId": "0f32fdf7-da19-4408-e17d-5806af8b729a"
      },
      "source": [
        "text = \"이순신은 조선 중기의 무신이다.\"\n",
        "tokenized_text = list(hgtk.text.decompose(text))\n",
        "print(tokenized_text)\n",
        "# ㅇ ㅣ ㅅ ㅜ ㄴ ㅅ ㅣ ... "
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ㅇ', 'ㅣ', 'ᴥ', 'ㅅ', 'ㅜ', 'ㄴ', 'ᴥ', 'ㅅ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㅈ', 'ㅗ', 'ᴥ', 'ㅅ', 'ㅓ', 'ㄴ', 'ᴥ', ' ', 'ㅈ', 'ㅜ', 'ㅇ', 'ᴥ', 'ㄱ', 'ㅣ', 'ᴥ', 'ㅇ', 'ㅢ', 'ᴥ', ' ', 'ㅁ', 'ㅜ', 'ᴥ', 'ㅅ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅣ', 'ᴥ', 'ㄷ', 'ㅏ', 'ᴥ', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cqlMZJgXD_gz"
      },
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self):\n",
        "        self.tokenizer_type_list = [\"word\", \"morph\", \"syllable\", \"jaso\"]\n",
        "        self.pad_token = \"<pad>\"\n",
        "        self.max_seq_length = 10\n",
        "        self.padding = False\n",
        "    def tokenize(self, text, tokenizer_type): \n",
        "        assert tokenizer_type in self.tokenizer_type_list, \"정의되지 않은 tokenizer_type입니다.\"\n",
        "        if tokenizer_type == \"word\":\n",
        "            tokenized_text = text.split(\" \")\n",
        "        elif tokenizer_type == \"morph\":\n",
        "            tokenized_text = [lemma[0] for lemma in mecab.pos(text)]\n",
        "        elif tokenizer_type == \"syllable\":\n",
        "            tokenized_text = list(text)\n",
        "        elif tokenizer_type == \"jaso\":\n",
        "            tokenized_text = list(hgtk.text.decompose(text))\n",
        "        if self.padding:\n",
        "            tokenized_text += [self.pad_token] * (self.max_seq_length - len(tokenized_text))\n",
        "            return tokenized_text[:self.max_seq_length]\n",
        "        else:\n",
        "            return tokenized_text[:self.max_seq_length]\n",
        "    def batch_tokenize(self, texts, tokenizer_type):\n",
        "        for i, text in enumerate(texts):\n",
        "            texts[i] = self.tokenize(text, tokenizer_type)\n",
        "        return texts"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "StfkrgZvEIY2"
      },
      "source": [
        "my_tokenizer = Tokenizer()\n",
        "my_tokenizer.pad_token = \"[PAD]\"\n",
        "my_tokenizer.max_seq_length = 20\n",
        "my_tokenizer.padding = True"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8-xKOWtpEKdB",
        "outputId": "49125b53-0f40-4a4f-87a5-92475c6823df"
      },
      "source": [
        "print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다.\", \"jaso\"))\n",
        "print(my_tokenizer.batch_tokenize([\"이순신은 조선 중기의 무신이다.\", \"그는 임진왜란을 승리로 이끌었다.\"], \"jaso\"))"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ㅇ', 'ㅣ', 'ᴥ', 'ㅅ', 'ㅜ', 'ㄴ', 'ᴥ', 'ㅅ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㅈ', 'ㅗ', 'ᴥ', 'ㅅ']\n",
            "[['ㅇ', 'ㅣ', 'ᴥ', 'ㅅ', 'ㅜ', 'ㄴ', 'ᴥ', 'ㅅ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㅈ', 'ㅗ', 'ᴥ', 'ㅅ'], ['ㄱ', 'ㅡ', 'ᴥ', 'ㄴ', 'ㅡ', 'ㄴ', 'ᴥ', ' ', 'ㅇ', 'ㅣ', 'ㅁ', 'ᴥ', 'ㅈ', 'ㅣ', 'ㄴ', 'ᴥ', 'ㅇ', 'ㅙ', 'ᴥ', 'ㄹ']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "c2ppAG0FGS8h"
      },
      "source": [
        "## WordPiece tokenizing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SWut4yYlnFH-",
        "outputId": "4138290a-4a5b-4a49-cb8f-d64159397b66"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.11.0-py3-none-any.whl (2.9 MB)\n",
            "\u001b[K     |████████████████████████████████| 2.9 MB 4.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting huggingface-hub>=0.0.17\n",
            "  Downloading huggingface_hub-0.0.17-py3-none-any.whl (52 kB)\n",
            "\u001b[K     |████████████████████████████████| 52 kB 1.4 MB/s \n",
            "\u001b[?25hCollecting pyyaml>=5.1\n",
            "  Downloading PyYAML-5.4.1-cp37-cp37m-manylinux1_x86_64.whl (636 kB)\n",
            "\u001b[K     |████████████████████████████████| 636 kB 48.3 MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.7/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.7/dist-packages (from transformers) (4.62.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.7/dist-packages (from transformers) (1.19.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.7/dist-packages (from transformers) (21.0)\n",
            "Requirement already satisfied: importlib-metadata in /usr/local/lib/python3.7/dist-packages (from transformers) (4.8.1)\n",
            "Collecting tokenizers<0.11,>=0.10.1\n",
            "  Downloading tokenizers-0.10.3-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.3 MB)\n",
            "\u001b[K     |████████████████████████████████| 3.3 MB 24.8 MB/s \n",
            "\u001b[?25hCollecting sacremoses\n",
            "  Downloading sacremoses-0.0.46-py3-none-any.whl (895 kB)\n",
            "\u001b[K     |████████████████████████████████| 895 kB 44.2 MB/s \n",
            "\u001b[?25hRequirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from huggingface-hub>=0.0.17->transformers) (3.7.4.3)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging>=20.0->transformers) (2.4.7)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.7/dist-packages (from importlib-metadata->transformers) (3.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2021.5.30)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->transformers) (2.10)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.15.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (1.0.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.7/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Installing collected packages: tokenizers, sacremoses, pyyaml, huggingface-hub, transformers\n",
            "  Attempting uninstall: pyyaml\n",
            "    Found existing installation: PyYAML 3.13\n",
            "    Uninstalling PyYAML-3.13:\n",
            "      Successfully uninstalled PyYAML-3.13\n",
            "Successfully installed huggingface-hub-0.0.17 pyyaml-5.4.1 sacremoses-0.0.46 tokenizers-0.10.3 transformers-4.11.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "szyYpZ0DRQT3"
      },
      "source": [
        "!mkdir wordPieceTokenizer"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZB0YedROqe0",
        "outputId": "6de8907f-643c-4a8d-c006-39149af654cc"
      },
      "source": [
        "from tokenizers import BertWordPieceTokenizer #tokenizer안에 Bert를 위한 WordPieceTokenizer가 들어있다\n",
        "\n",
        "# Initialize an empty tokenizer\n",
        "wp_tokenizer = BertWordPieceTokenizer(\n",
        "    clean_text=True,    # [이순신, ##은, ' ', 조선]-> cleantext를 True로 주면 ' '와 같은건 지워준다. 그리고 Bert도 cleantext기반으로 학습한다!!\n",
        "    handle_chinese_chars=True, #본문내에 존재하는 한자들이 글자단위로 분리가 된다(중국어는 띄어쓰기라는게 없다. 분석시 한음절 단위로 분석해야)\n",
        "    strip_accents=False,    # True: [YepHamza] -> [Yep, Hamza]\n",
        "    lowercase=False,  #모든 알파벳을 다 소문자로 바꿔준다. False로 주는게 더 성능이 좋다\n",
        ")\n",
        "'''\n",
        "위는 tokenizer에 대한 option을 만들어 준것\n",
        "아래는 train시키는 것(word piece tokenizing학습이 진행된다)\n",
        "'''\n",
        "# And then train\n",
        "wp_tokenizer.train(\n",
        "    files=\"my_data/wiki_20190620_small.txt\",\n",
        "    vocab_size=10000,#vocab개수를 10000로 하고 싶다. 이게 개수가 많으면, 거의 음절 단위로 다 잘라지게 된다 \n",
        "    min_frequency=2,#2개 이하로 등장하는 애는 vocab목록으로 만들지 않겠다\n",
        "    show_progress=True,\n",
        "    special_tokens=[\"[PAD]\", \"[UNK]\", \"[CLS]\", \"[SEP]\", \"[MASK]\"],#special token은 왼쪽과 같이 hard fix돼 있다. padding, unknown, 맨앞단, 맨뒷단, masking 을 위한 토큰 \n",
        "    limit_alphabet=1000,\n",
        "    wordpieces_prefix=\"##\"\n",
        ")\n",
        "\n",
        "# Save the files\n",
        "wp_tokenizer.save_model(\"wordPieceTokenizer\", \"my_tokenizer\")"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['wordPieceTokenizer/my_tokenizer-vocab.txt']"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SmRK4AFFIXBg",
        "outputId": "427036fb-651d-46ef-9ca1-200ef1e7fd79"
      },
      "source": [
        "print(wp_tokenizer.get_vocab_size())"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "10000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kG7GtaevKRLH",
        "outputId": "7e331159-70ac-452b-f9bc-5eb863d51e14"
      },
      "source": [
        "text = \"이순신은 조선 중기의 무신이다.\"\n",
        "tokenized_text = wp_tokenizer.encode(text)\n",
        "print(tokenized_text)\n",
        "print(tokenized_text.tokens)\n",
        "print(tokenized_text.ids)"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Encoding(num_tokens=10, attributes=[ids, type_ids, tokens, offsets, attention_mask, special_tokens_mask, overflowing])\n",
            "['이', '##순', '##신은', '조선', '중', '##기의', '무', '##신이', '##다', '.']\n",
            "[707, 1057, 7630, 2002, 755, 2606, 453, 8513, 1038, 16]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VfEKVuu6GnW7"
      },
      "source": [
        "class Tokenizer:\n",
        "    def __init__(self):\n",
        "        self.tokenizer_type_list = [\"word\", \"morph\", \"syllable\", \"jaso\", \"wordPiece\"] # tokenizer타입에 wordpiece를 추가!!\n",
        "        self.pad_token = \"<pad>\"\n",
        "        self.max_seq_length = 10\n",
        "        self.padding = False\n",
        "    def tokenize(self, text, tokenizer_type): \n",
        "        assert tokenizer_type in self.tokenizer_type_list, \"정의되지 않은 tokenizer_type입니다.\"\n",
        "        if tokenizer_type == \"word\":\n",
        "            tokenized_text = text.split(\" \")\n",
        "        elif tokenizer_type == \"morph\":\n",
        "            tokenized_text = [lemma[0] for lemma in mecab.pos(text)]\n",
        "        elif tokenizer_type == \"syllable\":\n",
        "            tokenized_text = list(text)\n",
        "        elif tokenizer_type == \"jaso\":\n",
        "            tokenized_text = list(hgtk.text.decompose(text))\n",
        "        elif tokenizer_type == \"wordPiece\":\n",
        "            tokenized_text = wp_tokenizer.encode(text).tokens\n",
        "        if self.padding:\n",
        "            tokenized_text += [self.pad_token] * (self.max_seq_length - len(tokenized_text))\n",
        "            return tokenized_text[:self.max_seq_length]\n",
        "        else:\n",
        "            return tokenized_text[:self.max_seq_length]\n",
        "    def batch_tokenize(self, texts, tokenizer_type):\n",
        "        for i, text in enumerate(texts):\n",
        "            texts[i] = self.tokenize(text, tokenizer_type)\n",
        "        return texts"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "anIwM9sZR_u8"
      },
      "source": [
        "my_tokenizer = Tokenizer()\n",
        "my_tokenizer.pad_token = \"[PAD]\"\n",
        "my_tokenizer.max_seq_length = 10\n",
        "my_tokenizer.padding = True"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vG8zOIN1SBLj",
        "outputId": "8cdfb2f9-2cfa-4eea-f741-1933e19502a6"
      },
      "source": [
        "print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다.\", \"wordPiece\"))\n",
        "print(my_tokenizer.batch_tokenize([\"이순신은 조선 중기의 무신이다.\", \"그는 임진왜란을 승리로 이끌었다.\"], \"wordPiece\"))"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이', '##순', '##신은', '조선', '중', '##기의', '무', '##신이', '##다', '.']\n",
            "[['이', '##순', '##신은', '조선', '중', '##기의', '무', '##신이', '##다', '.'], ['그는', '임진', '##왜', '##란을', '승리', '##로', '이끌었다', '.', '[PAD]', '[PAD]']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RumHmOm4nH5C"
      },
      "source": [
        "구현된 tokenizing 함수들을 모두 확인해보겠습니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "05tvdp1uSEss",
        "outputId": "7081ebdc-2f25-4368-8330-952105aef306"
      },
      "source": [
        "print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다.\", \"word\"))\n",
        "print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다.\", \"morph\"))\n",
        "print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다.\", \"syllable\"))\n",
        "print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다.\", \"jaso\"))\n",
        "print(my_tokenizer.tokenize(\"이순신은 조선 중기의 무신이다.\", \"wordPiece\"))"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['이순신은', '조선', '중기의', '무신이다.', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]', '[PAD]']\n",
            "['이순신', '은', '조선', '중기', '의', '무신', '이', '다', '.', '[PAD]']\n",
            "['이', '순', '신', '은', ' ', '조', '선', ' ', '중', '기']\n",
            "['ㅇ', 'ㅣ', 'ᴥ', 'ㅅ', 'ㅜ', 'ㄴ', 'ᴥ', 'ㅅ', 'ㅣ', 'ㄴ']\n",
            "['이', '##순', '##신은', '조선', '중', '##기의', '무', '##신이', '##다', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lgIH8nwOSeP3"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}